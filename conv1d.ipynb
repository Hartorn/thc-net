{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:43.941660Z",
     "start_time": "2020-05-25T20:59:43.833639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:44.433824Z",
     "start_time": "2020-05-25T20:59:43.943368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import os\\nfrom pathlib import Path\\n\\nfrom requests import get\\nimport pandas as pd\\nimport numpy as np\\n\\nnp.random.seed(0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import roc_auc_score\\n\\nimport logging\\n\\nlogging.basicConfig(level=logging.WARN)\";\n",
       "                var nbb_formatted_code = \"import os\\nfrom pathlib import Path\\n\\nfrom requests import get\\nimport pandas as pd\\nimport numpy as np\\n\\nnp.random.seed(0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import roc_auc_score\\n\\nimport logging\\n\\nlogging.basicConfig(level=logging.WARN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.767278Z",
     "start_time": "2020-05-25T20:59:44.435849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from tensorflow.keras import Model, Input\\nfrom tensorflow.keras.layers import (\\n    Conv1D,\\n    SpatialDropout1D,\\n    LocallyConnected1D,\\n    Dense,\\n    Reshape,\\n    MaxPooling1D,\\n    BatchNormalization,\\n    Activation,\\n    LayerNormalization,\\n)\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nfrom tensorflow.keras.utils import to_categorical\\n\\nfrom tensorflow_addons.activations import mish\\nfrom tensorflow_addons.optimizers import RectifiedAdam, Lookahead\\nfrom tensorflow_addons.layers import WeightNormalization\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n\\nfrom itertools import repeat\\nfrom concurrent.futures import ProcessPoolExecutor as PoolExecutor\\n\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.pyplot import imshow\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"from tensorflow.keras import Model, Input\\nfrom tensorflow.keras.layers import (\\n    Conv1D,\\n    SpatialDropout1D,\\n    LocallyConnected1D,\\n    Dense,\\n    Reshape,\\n    MaxPooling1D,\\n    BatchNormalization,\\n    Activation,\\n    LayerNormalization,\\n)\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nfrom tensorflow.keras.utils import to_categorical\\n\\nfrom tensorflow_addons.activations import mish\\nfrom tensorflow_addons.optimizers import RectifiedAdam, Lookahead\\nfrom tensorflow_addons.layers import WeightNormalization\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n\\nfrom itertools import repeat\\nfrom concurrent.futures import ProcessPoolExecutor as PoolExecutor\\n\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.pyplot import imshow\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    SpatialDropout1D,\n",
    "    LocallyConnected1D,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    LayerNormalization,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow_addons.activations import mish\n",
    "from tensorflow_addons.optimizers import RectifiedAdam, Lookahead\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from itertools import repeat\n",
    "from concurrent.futures import ProcessPoolExecutor as PoolExecutor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import tensorflow_addons as tfa\\n\\ntfa.options.TF_ADDONS_PY_OPS = True\";\n",
       "                var nbb_formatted_code = \"import tensorflow_addons as tfa\\n\\ntfa.options.TF_ADDONS_PY_OPS = True\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "tfa.options.TF_ADDONS_PY_OPS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.781039Z",
     "start_time": "2020-05-25T20:59:45.769170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def word_to_np_array(word, cut_length):\\n    result = np.zeros(cut_length, dtype=\\\"uint8\\\")\\n    for i, letter in enumerate(word[:cut_length]):\\n        result[i] = ord(letter)\\n    return result\";\n",
       "                var nbb_formatted_code = \"def word_to_np_array(word, cut_length):\\n    result = np.zeros(cut_length, dtype=\\\"uint8\\\")\\n    for i, letter in enumerate(word[:cut_length]):\\n        result[i] = ord(letter)\\n    return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def word_to_np_array(word, cut_length):\n",
    "    result = np.zeros(cut_length, dtype=\"uint8\")\n",
    "    for i, letter in enumerate(word[:cut_length]):\n",
    "        result[i] = ord(letter)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.893504Z",
     "start_time": "2020-05-25T20:59:45.782485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def line_to_img(line, cut_length):\\n    result = np.zeros((line.shape[0], cut_length), dtype=\\\"uint8\\\")\\n    for i in range(line.shape[0]):\\n        result[i] = word_to_np_array(line[i], cut_length)\\n    return result\";\n",
       "                var nbb_formatted_code = \"def line_to_img(line, cut_length):\\n    result = np.zeros((line.shape[0], cut_length), dtype=\\\"uint8\\\")\\n    for i in range(line.shape[0]):\\n        result[i] = word_to_np_array(line[i], cut_length)\\n    return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def line_to_img(line, cut_length):\n",
    "    result = np.zeros((line.shape[0], cut_length), dtype=\"uint8\")\n",
    "    for i in range(line.shape[0]):\n",
    "        result[i] = word_to_np_array(line[i], cut_length)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.016629Z",
     "start_time": "2020-05-25T20:59:45.895831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def do_parallel_numpy(map_func, iter_params, constant_params=None):\\n    repeated_params = (\\n        [] if constant_params is None else list(map(repeat, constant_params))\\n    )\\n    results = None\\n    with PoolExecutor() as executor:\\n        results = np.stack(\\n            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\\n        )\\n    return results\";\n",
       "                var nbb_formatted_code = \"def do_parallel_numpy(map_func, iter_params, constant_params=None):\\n    repeated_params = (\\n        [] if constant_params is None else list(map(repeat, constant_params))\\n    )\\n    results = None\\n    with PoolExecutor() as executor:\\n        results = np.stack(\\n            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\\n        )\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_parallel_numpy(map_func, iter_params, constant_params=None):\n",
    "    repeated_params = (\n",
    "        [] if constant_params is None else list(map(repeat, constant_params))\n",
    "    )\n",
    "    results = None\n",
    "    with PoolExecutor() as executor:\n",
    "        results = np.stack(\n",
    "            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.106802Z",
     "start_time": "2020-05-25T20:59:46.020842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def download(url, out, force=False, verify=True):\\n    out.parent.mkdir(parents=True, exist_ok=True)\\n    if force and out.exists():\\n        print(f\\\"Removing file at {str(out)}\\\")\\n        out.unlink()\\n\\n    if out.exists():\\n        print(\\\"File already exists.\\\")\\n        return\\n    print(f\\\"Downloading {url} at {str(out)} ...\\\")\\n    # open in binary mode\\n    with out.open(mode=\\\"wb\\\") as file:\\n        # get request\\n        response = get(url, verify=verify)\\n        for chunk in response.iter_content(100000):\\n            # write to file\\n            file.write(chunk)\";\n",
       "                var nbb_formatted_code = \"def download(url, out, force=False, verify=True):\\n    out.parent.mkdir(parents=True, exist_ok=True)\\n    if force and out.exists():\\n        print(f\\\"Removing file at {str(out)}\\\")\\n        out.unlink()\\n\\n    if out.exists():\\n        print(\\\"File already exists.\\\")\\n        return\\n    print(f\\\"Downloading {url} at {str(out)} ...\\\")\\n    # open in binary mode\\n    with out.open(mode=\\\"wb\\\") as file:\\n        # get request\\n        response = get(url, verify=verify)\\n        for chunk in response.iter_content(100000):\\n            # write to file\\n            file.write(chunk)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download(url, out, force=False, verify=True):\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if force and out.exists():\n",
    "        print(f\"Removing file at {str(out)}\")\n",
    "        out.unlink()\n",
    "\n",
    "    if out.exists():\n",
    "        print(\"File already exists.\")\n",
    "        return\n",
    "    print(f\"Downloading {url} at {str(out)} ...\")\n",
    "    # open in binary mode\n",
    "    with out.open(mode=\"wb\") as file:\n",
    "        # get request\n",
    "        response = get(url, verify=verify)\n",
    "        for chunk in response.iter_content(100000):\n",
    "            # write to file\n",
    "            file.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.210035Z",
     "start_time": "2020-05-25T20:59:46.110562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def plot_history(history):\\n    loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" not in s]\\n    val_loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" in s]\\n    acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" not in s]\\n    val_acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" in s]\\n\\n    if len(loss_list) == 0:\\n        print(\\\"Loss is missing in history\\\")\\n        return\\n\\n    ## As loss always exists\\n    epochs = range(1, len(history.history[loss_list[0]]) + 1)\\n\\n    ## Loss\\n    plt.figure(1)\\n    for l in loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"b\\\",\\n            label=\\\"Training loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n    for l in val_loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"g\\\",\\n            label=\\\"Validation loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n\\n    plt.title(\\\"Loss\\\")\\n    plt.xlabel(\\\"Epochs\\\")\\n    plt.ylabel(\\\"Loss\\\")\\n    plt.legend()\\n\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def plot_history(history):\\n    loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" not in s]\\n    val_loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" in s]\\n    acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" not in s]\\n    val_acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" in s]\\n\\n    if len(loss_list) == 0:\\n        print(\\\"Loss is missing in history\\\")\\n        return\\n\\n    ## As loss always exists\\n    epochs = range(1, len(history.history[loss_list[0]]) + 1)\\n\\n    ## Loss\\n    plt.figure(1)\\n    for l in loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"b\\\",\\n            label=\\\"Training loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n    for l in val_loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"g\\\",\\n            label=\\\"Validation loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n\\n    plt.title(\\\"Loss\\\")\\n    plt.xlabel(\\\"Epochs\\\")\\n    plt.ylabel(\\\"Loss\\\")\\n    plt.legend()\\n\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if \"loss\" in s and \"val\" not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if \"loss\" in s and \"val\" in s]\n",
    "    acc_list = [s for s in history.history.keys() if \"AUC\" in s and \"val\" not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if \"AUC\" in s and \"val\" in s]\n",
    "\n",
    "    if len(loss_list) == 0:\n",
    "        print(\"Loss is missing in history\")\n",
    "        return\n",
    "\n",
    "    ## As loss always exists\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "\n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(\n",
    "            epochs,\n",
    "            history.history[l],\n",
    "            \"b\",\n",
    "            label=\"Training loss (\"\n",
    "            + str(str(format(history.history[l][-1], \".5f\")) + \")\"),\n",
    "        )\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(\n",
    "            epochs,\n",
    "            history.history[l],\n",
    "            \"g\",\n",
    "            label=\"Validation loss (\"\n",
    "            + str(str(format(history.history[l][-1], \".5f\")) + \")\"),\n",
    "        )\n",
    "\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.276902Z",
     "start_time": "2020-05-25T20:59:46.212058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "File already exists.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"url = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\\"\\nurl_test = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\\\"\\n\\ndataset_name = \\\"census-income\\\"\\nout = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\".csv\\\")\\nout_test = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\"_test.csv\\\")\\n\\ndownload(url, out, force=False)\\ndownload(url_test, out_test, force=False)\";\n",
       "                var nbb_formatted_code = \"url = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\\"\\nurl_test = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\\\"\\n\\ndataset_name = \\\"census-income\\\"\\nout = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\".csv\\\")\\nout_test = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\"_test.csv\\\")\\n\\ndownload(url, out, force=False)\\ndownload(url_test, out_test, force=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "url_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "\n",
    "dataset_name = \"census-income\"\n",
    "out = Path(os.getcwd() + \"/data/\" + dataset_name + \".csv\")\n",
    "out_test = Path(os.getcwd() + \"/data/\" + dataset_name + \"_test.csv\")\n",
    "\n",
    "download(url, out, force=False)\n",
    "download(url_test, out_test, force=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.361578Z",
     "start_time": "2020-05-25T20:59:46.279187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"cols = [\\n    \\\"age\\\",\\n    \\\"workclass\\\",\\n    \\\"fnlwgt\\\",\\n    \\\"education\\\",\\n    \\\"education-num\\\",\\n    \\\"marital-status\\\",\\n    \\\"occupation\\\",\\n    \\\"relationship\\\",\\n    \\\"race\\\",\\n    \\\"sex\\\",\\n    \\\"capital-gain\\\",\\n    \\\"capital-loss\\\",\\n    \\\"hours-per-week\\\",\\n    \\\"native-country\\\",\\n    \\\"target\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"cols = [\\n    \\\"age\\\",\\n    \\\"workclass\\\",\\n    \\\"fnlwgt\\\",\\n    \\\"education\\\",\\n    \\\"education-num\\\",\\n    \\\"marital-status\\\",\\n    \\\"occupation\\\",\\n    \\\"relationship\\\",\\n    \\\"race\\\",\\n    \\\"sex\\\",\\n    \\\"capital-gain\\\",\\n    \\\"capital-loss\\\",\\n    \\\"hours-per-week\\\",\\n    \\\"native-country\\\",\\n    \\\"target\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"target\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.557825Z",
     "start_time": "2020-05-25T20:59:46.365361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"train = pd.read_csv(out, names=cols)\\ntest = pd.read_csv(out_test, names=cols, skiprows=2)\\ntarget = \\\"target\\\"\\n\\ntrain[target] = train[target].str.strip()\\n# Test has . in label, let's clean it\\ntest[target] = test[target].str.strip().str.strip(\\\".\\\")\";\n",
       "                var nbb_formatted_code = \"train = pd.read_csv(out, names=cols)\\ntest = pd.read_csv(out_test, names=cols, skiprows=2)\\ntarget = \\\"target\\\"\\n\\ntrain[target] = train[target].str.strip()\\n# Test has . in label, let's clean it\\ntest[target] = test[target].str.strip().str.strip(\\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(out, names=cols)\n",
    "test = pd.read_csv(out_test, names=cols, skiprows=2)\n",
    "target = \"target\"\n",
    "\n",
    "train[target] = train[target].str.strip()\n",
    "# Test has . in label, let's clean it\n",
    "test[target] = test[target].str.strip().str.strip(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.566032Z",
     "start_time": "2020-05-25T20:59:46.559340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 105;\n",
       "                var nbb_unformatted_code = \"target_encoder = LabelEncoder()\";\n",
       "                var nbb_formatted_code = \"target_encoder = LabelEncoder()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.661768Z",
     "start_time": "2020-05-25T20:59:46.567593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 106;\n",
       "                var nbb_unformatted_code = \"train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\\ntest[target] = target_encoder.transform(test[target].values.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\\ntest[target] = target_encoder.transform(test[target].values.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\n",
    "test[target] = target_encoder.transform(test[target].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.745241Z",
     "start_time": "2020-05-25T20:59:46.663423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fnlwgt',\n",
       " 'marital-status',\n",
       " 'race',\n",
       " 'education-num',\n",
       " 'hours-per-week',\n",
       " 'capital-loss',\n",
       " 'native-country',\n",
       " 'relationship',\n",
       " 'workclass',\n",
       " 'education',\n",
       " 'sex',\n",
       " 'occupation',\n",
       " 'capital-gain',\n",
       " 'age']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"used_columns = list(set(train.columns.tolist()) - set([target]) - set([\\\"Set\\\"]))\\nused_columns\";\n",
       "                var nbb_formatted_code = \"used_columns = list(set(train.columns.tolist()) - set([target]) - set([\\\"Set\\\"]))\\nused_columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "used_columns = list(set(train.columns.tolist()) - set([target]) - set([\"Set\"]))\n",
    "used_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.405604Z",
     "start_time": "2020-05-25T20:59:46.747053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"train[\\\"Set\\\"] = np.random.choice(\\n    [\\\"train\\\", \\\"valid\\\"], p=[0.8, 0.2], size=(train.shape[0],)\\n)\\n\\ntrain_indices = train[train.Set == \\\"train\\\"].index\\nvalid_indices = train[train.Set == \\\"valid\\\"].index\\n\\nX_train = np.char.strip(train[used_columns].values[train_indices].astype(\\\"str\\\"))\\nX_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\\\"str\\\"))\\n\\ny_train = train[target].values[train_indices]\\ny_valid = train[target].values[valid_indices]\\n\\n# Test here should be ignored for training, only purpose is benching with paper values\\nX_test = np.char.strip(test[used_columns].values.astype(\\\"str\\\"))\\ny_test = test[target].values\\n\\ndel train, test, train_indices, valid_indices\";\n",
       "                var nbb_formatted_code = \"train[\\\"Set\\\"] = np.random.choice(\\n    [\\\"train\\\", \\\"valid\\\"], p=[0.8, 0.2], size=(train.shape[0],)\\n)\\n\\ntrain_indices = train[train.Set == \\\"train\\\"].index\\nvalid_indices = train[train.Set == \\\"valid\\\"].index\\n\\nX_train = np.char.strip(train[used_columns].values[train_indices].astype(\\\"str\\\"))\\nX_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\\\"str\\\"))\\n\\ny_train = train[target].values[train_indices]\\ny_valid = train[target].values[valid_indices]\\n\\n# Test here should be ignored for training, only purpose is benching with paper values\\nX_test = np.char.strip(test[used_columns].values.astype(\\\"str\\\"))\\ny_test = test[target].values\\n\\ndel train, test, train_indices, valid_indices\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"Set\"] = np.random.choice(\n",
    "    [\"train\", \"valid\"], p=[0.8, 0.2], size=(train.shape[0],)\n",
    ")\n",
    "\n",
    "train_indices = train[train.Set == \"train\"].index\n",
    "valid_indices = train[train.Set == \"valid\"].index\n",
    "\n",
    "X_train = np.char.strip(train[used_columns].values[train_indices].astype(\"str\"))\n",
    "X_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\"str\"))\n",
    "\n",
    "y_train = train[target].values[train_indices]\n",
    "y_valid = train[target].values[valid_indices]\n",
    "\n",
    "# Test here should be ignored for training, only purpose is benching with paper values\n",
    "X_test = np.char.strip(test[used_columns].values.astype(\"str\"))\n",
    "y_test = test[target].values\n",
    "\n",
    "del train, test, train_indices, valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.412417Z",
     "start_time": "2020-05-25T20:59:47.406951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26108, 14)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"X_train.shape\";\n",
       "                var nbb_formatted_code = \"X_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.573456Z",
     "start_time": "2020-05-25T20:59:47.413649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"INPUT_DIM = X_train.shape[1]\\nNB_CHANNELS = np.vectorize(len)(X_train).max()\\nNB_CHANNELS\";\n",
       "                var nbb_formatted_code = \"INPUT_DIM = X_train.shape[1]\\nNB_CHANNELS = np.vectorize(len)(X_train).max()\\nNB_CHANNELS\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIM = X_train.shape[1]\n",
    "NB_CHANNELS = np.vectorize(len)(X_train).max()\n",
    "NB_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.616024Z",
     "start_time": "2020-05-25T20:59:47.574971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"line_to_img(X_train[0], 27).shape\";\n",
       "                var nbb_formatted_code = \"line_to_img(X_train[0], 27).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_to_img(X_train[0], 27).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.007709Z",
     "start_time": "2020-05-25T20:59:47.617541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 110;\n",
       "                var nbb_unformatted_code = \"X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\\nX_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\\nX_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])\";\n",
       "                var nbb_formatted_code = \"X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\\nX_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\\nX_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\n",
    "X_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\n",
    "X_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T19:22:09.609604Z",
     "start_time": "2020-05-25T19:22:09.602138Z"
    }
   },
   "source": [
    "Y_train_preproc = to_categorical(y_train)\n",
    "Y_valid_preproc = to_categorical(y_valid)\n",
    "Y_test_preproc = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.061348Z",
     "start_time": "2020-05-25T21:00:00.017086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\\n    activation = mish\\n    optimizer = (\\n        Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\\n    )\\n\\n    input_layer = Input(shape=(input_dim, nb_channels), name=\\\"input\\\")\\n    x_layer = input_layer\\n    for i, conv_layer in enumerate(conv_dim):\\n        name = f\\\"block_conv_{i}_\\\"\\n        x_layer = Conv1D(\\n            filters=conv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"conv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    for i, lconv_layer in enumerate(lconv_dim):\\n        name = f\\\"block_lconv_{i}_\\\"\\n        x_layer = LocallyConnected1D(\\n            filters=lconv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"lconv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\\n    x_layer = Reshape((input_dim * nb_filters,), name=\\\"reshape\\\")(x_layer)\\n    x_layer = Dense(1, activation=\\\"sigmoid\\\", name=\\\"output\\\")(x_layer)\\n\\n    model = Model(inputs=[input_layer], outputs=[x_layer], name=\\\"first_model\\\")\\n    model.compile(loss=\\\"binary_crossentropy\\\", optimizer=optimizer)\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\\n    activation = mish\\n    optimizer = Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\\n\\n    input_layer = Input(shape=(input_dim, nb_channels), name=\\\"input\\\")\\n    x_layer = input_layer\\n    for i, conv_layer in enumerate(conv_dim):\\n        name = f\\\"block_conv_{i}_\\\"\\n        x_layer = Conv1D(\\n            filters=conv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"conv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    for i, lconv_layer in enumerate(lconv_dim):\\n        name = f\\\"block_lconv_{i}_\\\"\\n        x_layer = LocallyConnected1D(\\n            filters=lconv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"lconv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\\n    x_layer = Reshape((input_dim * nb_filters,), name=\\\"reshape\\\")(x_layer)\\n    x_layer = Dense(1, activation=\\\"sigmoid\\\", name=\\\"output\\\")(x_layer)\\n\\n    model = Model(inputs=[input_layer], outputs=[x_layer], name=\\\"first_model\\\")\\n    model.compile(loss=\\\"binary_crossentropy\\\", optimizer=optimizer)\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\n",
    "    activation = mish\n",
    "    optimizer = Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\n",
    "\n",
    "    input_layer = Input(shape=(input_dim, nb_channels), name=\"input\")\n",
    "    x_layer = input_layer\n",
    "    for i, conv_layer in enumerate(conv_dim):\n",
    "        name = f\"block_conv_{i}_\"\n",
    "        x_layer = Conv1D(\n",
    "            filters=conv_layer,\n",
    "            padding=\"valid\",\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            name=name + \"conv\",\n",
    "            use_bias=False,\n",
    "            activation=None,\n",
    "        )(x_layer)\n",
    "        x_layer = BatchNormalization(name=name + \"nb\")(x_layer)\n",
    "        x_layer = Activation(activation, name=name + \"activation\")(x_layer)\n",
    "\n",
    "    for i, lconv_layer in enumerate(lconv_dim):\n",
    "        name = f\"block_lconv_{i}_\"\n",
    "        x_layer = LocallyConnected1D(\n",
    "            filters=lconv_layer,\n",
    "            padding=\"valid\",\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            name=name + \"lconv\",\n",
    "            use_bias=False,\n",
    "            activation=None,\n",
    "        )(x_layer)\n",
    "        x_layer = BatchNormalization(name=name + \"nb\")(x_layer)\n",
    "        x_layer = Activation(activation, name=name + \"activation\")(x_layer)\n",
    "\n",
    "    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\n",
    "    x_layer = Reshape((input_dim * nb_filters,), name=\"reshape\")(x_layer)\n",
    "    x_layer = Dense(1, activation=\"sigmoid\", name=\"output\")(x_layer)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x_layer], name=\"first_model\")\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.979562Z",
     "start_time": "2020-05-25T21:00:00.062758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])\";\n",
       "                var nbb_formatted_code = \"model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.994383Z",
     "start_time": "2020-05-25T21:00:00.981768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"first_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 14, 26)]          0         \n",
      "_________________________________________________________________\n",
      "block_conv_0_conv (Conv1D)   (None, 14, 64)            1664      \n",
      "_________________________________________________________________\n",
      "block_conv_0_nb (BatchNormal (None, 14, 64)            256       \n",
      "_________________________________________________________________\n",
      "block_conv_0_activation (Act (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "block_lconv_0_lconv (Locally (None, 14, 128)           114688    \n",
      "_________________________________________________________________\n",
      "block_lconv_0_nb (BatchNorma (None, 14, 128)           512       \n",
      "_________________________________________________________________\n",
      "block_lconv_0_activation (Ac (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "block_lconv_1_lconv (Locally (None, 14, 64)            114688    \n",
      "_________________________________________________________________\n",
      "block_lconv_1_nb (BatchNorma (None, 14, 64)            256       \n",
      "_________________________________________________________________\n",
      "block_lconv_1_activation (Ac (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "block_lconv_2_lconv (Locally (None, 14, 32)            28672     \n",
      "_________________________________________________________________\n",
      "block_lconv_2_nb (BatchNorma (None, 14, 32)            128       \n",
      "_________________________________________________________________\n",
      "block_lconv_2_activation (Ac (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 261,313\n",
      "Trainable params: 260,737\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"model.summary()\";\n",
       "                var nbb_formatted_code = \"model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:01.114121Z",
     "start_time": "2020-05-25T21:00:00.997404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26072,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"y_train.shape\";\n",
       "                var nbb_formatted_code = \"y_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.717722Z",
     "start_time": "2020-05-25T21:00:01.118492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 6s 225ms/step - loss: 0.4962 - val_loss: 0.6910\n",
      "Epoch 2/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3726 - val_loss: 0.6915\n",
      "Epoch 3/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.3486 - val_loss: 0.6933\n",
      "Epoch 4/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3396 - val_loss: 0.6946\n",
      "Epoch 5/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.3344 - val_loss: 0.6932\n",
      "Epoch 6/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3322 - val_loss: 0.6915\n",
      "Epoch 7/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.3315 - val_loss: 0.6775\n",
      "Epoch 8/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.3351 - val_loss: 0.6640\n",
      "Epoch 9/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.3300 - val_loss: 0.6425\n",
      "Epoch 10/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3265 - val_loss: 0.6162\n",
      "Epoch 11/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3241 - val_loss: 0.5571\n",
      "Epoch 12/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.3275 - val_loss: 0.5211\n",
      "Epoch 13/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.3210 - val_loss: 0.4861\n",
      "Epoch 14/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3191 - val_loss: 0.4764\n",
      "Epoch 15/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3191 - val_loss: 0.4176\n",
      "Epoch 16/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3153 - val_loss: 0.4063\n",
      "Epoch 17/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3136 - val_loss: 0.4058\n",
      "Epoch 18/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3166 - val_loss: 0.3539\n",
      "Epoch 19/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3128 - val_loss: 0.3659\n",
      "Epoch 20/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.3102 - val_loss: 0.3806\n",
      "Epoch 21/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.3068 - val_loss: 0.3590\n",
      "Epoch 22/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.3080 - val_loss: 0.3802\n",
      "Epoch 23/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.3075 - val_loss: 0.4105\n",
      "Epoch 24/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.3063 - val_loss: 0.3498\n",
      "Epoch 25/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3040 - val_loss: 0.3596\n",
      "Epoch 26/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3046 - val_loss: 0.3362\n",
      "Epoch 27/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3061 - val_loss: 0.3372\n",
      "Epoch 28/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3019 - val_loss: 0.3307\n",
      "Epoch 29/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.3053 - val_loss: 0.3565\n",
      "Epoch 30/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.3039 - val_loss: 0.3214\n",
      "Epoch 31/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3046 - val_loss: 0.3412\n",
      "Epoch 32/2000\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.3041 - val_loss: 0.3461\n",
      "Epoch 33/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.3014 - val_loss: 0.3176\n",
      "Epoch 34/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.3017 - val_loss: 0.3272\n",
      "Epoch 35/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.3025 - val_loss: 0.3291\n",
      "Epoch 36/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.3018 - val_loss: 0.3168\n",
      "Epoch 37/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.3027 - val_loss: 0.3344\n",
      "Epoch 38/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3004 - val_loss: 0.3266\n",
      "Epoch 39/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3009 - val_loss: 0.3156\n",
      "Epoch 40/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2999 - val_loss: 0.3158\n",
      "Epoch 41/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2991 - val_loss: 0.3304\n",
      "Epoch 42/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2996 - val_loss: 0.3167\n",
      "Epoch 43/2000\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.3001 - val_loss: 0.3090\n",
      "Epoch 44/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2994 - val_loss: 0.3204\n",
      "Epoch 45/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2996 - val_loss: 0.3215\n",
      "Epoch 46/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2998 - val_loss: 0.3074\n",
      "Epoch 47/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2979 - val_loss: 0.3113\n",
      "Epoch 48/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2984 - val_loss: 0.3095\n",
      "Epoch 49/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2981 - val_loss: 0.3191\n",
      "Epoch 50/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2981 - val_loss: 0.3179\n",
      "Epoch 51/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2976 - val_loss: 0.2976\n",
      "Epoch 52/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3010 - val_loss: 0.3113\n",
      "Epoch 53/2000\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.2964 - val_loss: 0.3113\n",
      "Epoch 54/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2970 - val_loss: 0.3067\n",
      "Epoch 55/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2965 - val_loss: 0.3316\n",
      "Epoch 56/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2963 - val_loss: 0.3146\n",
      "Epoch 57/2000\n",
      "26/26 [==============================] - 6s 219ms/step - loss: 0.2964 - val_loss: 0.3053\n",
      "Epoch 58/2000\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.2946 - val_loss: 0.3194\n",
      "Epoch 59/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2945 - val_loss: 0.3088\n",
      "Epoch 60/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2957 - val_loss: 0.3039\n",
      "Epoch 61/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2943 - val_loss: 0.2992\n",
      "Epoch 62/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2942 - val_loss: 0.3089\n",
      "Epoch 63/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2951 - val_loss: 0.3026\n",
      "Epoch 64/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2943 - val_loss: 0.3345\n",
      "Epoch 65/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2953 - val_loss: 0.3058\n",
      "Epoch 66/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2927 - val_loss: 0.3101\n",
      "Epoch 67/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2916 - val_loss: 0.3139\n",
      "Epoch 68/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2926 - val_loss: 0.3092\n",
      "Epoch 69/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2961 - val_loss: 0.3037\n",
      "Epoch 70/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2936 - val_loss: 0.3097\n",
      "Epoch 71/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2923 - val_loss: 0.2944\n",
      "Epoch 72/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2929 - val_loss: 0.3001\n",
      "Epoch 73/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2916 - val_loss: 0.2930\n",
      "Epoch 74/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2913 - val_loss: 0.2963\n",
      "Epoch 75/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2913 - val_loss: 0.2970\n",
      "Epoch 76/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2921 - val_loss: 0.2947\n",
      "Epoch 77/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2900 - val_loss: 0.2990\n",
      "Epoch 78/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2919 - val_loss: 0.2996\n",
      "Epoch 79/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2901 - val_loss: 0.3081\n",
      "Epoch 80/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2910 - val_loss: 0.2895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2911 - val_loss: 0.2957\n",
      "Epoch 82/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.2911 - val_loss: 0.2906\n",
      "Epoch 83/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2909 - val_loss: 0.3050\n",
      "Epoch 84/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2897 - val_loss: 0.2958\n",
      "Epoch 85/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2901 - val_loss: 0.2930\n",
      "Epoch 86/2000\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.2903 - val_loss: 0.3056\n",
      "Epoch 87/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2905 - val_loss: 0.2963\n",
      "Epoch 88/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2894 - val_loss: 0.2962\n",
      "Epoch 89/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2886 - val_loss: 0.3103\n",
      "Epoch 90/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2903 - val_loss: 0.2989\n",
      "Epoch 91/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2912 - val_loss: 0.2948\n",
      "Epoch 92/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2900 - val_loss: 0.2887\n",
      "Epoch 93/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2897 - val_loss: 0.2898\n",
      "Epoch 94/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2882 - val_loss: 0.2894\n",
      "Epoch 95/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2875 - val_loss: 0.2898\n",
      "Epoch 96/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2889 - val_loss: 0.2922\n",
      "Epoch 97/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2903 - val_loss: 0.3142\n",
      "Epoch 98/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2907 - val_loss: 0.2948\n",
      "Epoch 99/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2900 - val_loss: 0.3005\n",
      "Epoch 100/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2889 - val_loss: 0.2895\n",
      "Epoch 101/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2868 - val_loss: 0.2946\n",
      "Epoch 102/2000\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.2866 - val_loss: 0.2918\n",
      "Epoch 103/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2877 - val_loss: 0.2945\n",
      "Epoch 104/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2887 - val_loss: 0.2908\n",
      "Epoch 105/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2882 - val_loss: 0.2936\n",
      "Epoch 106/2000\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.2869 - val_loss: 0.2941\n",
      "Epoch 107/2000\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.2876 - val_loss: 0.2997\n",
      "Epoch 108/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2880 - val_loss: 0.2932\n",
      "Epoch 109/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2871 - val_loss: 0.2898\n",
      "Epoch 110/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2864 - val_loss: 0.2909\n",
      "Epoch 111/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2869 - val_loss: 0.2911\n",
      "Epoch 112/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2890 - val_loss: 0.2883\n",
      "Epoch 113/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2861 - val_loss: 0.2867\n",
      "Epoch 114/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2860 - val_loss: 0.2905\n",
      "Epoch 115/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2865 - val_loss: 0.2911\n",
      "Epoch 116/2000\n",
      "26/26 [==============================] - 6s 242ms/step - loss: 0.2859 - val_loss: 0.2940\n",
      "Epoch 117/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2865 - val_loss: 0.2903\n",
      "Epoch 118/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2852 - val_loss: 0.2900\n",
      "Epoch 119/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2852 - val_loss: 0.2903\n",
      "Epoch 120/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2847 - val_loss: 0.2893\n",
      "Epoch 121/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2849 - val_loss: 0.2856\n",
      "Epoch 122/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2875 - val_loss: 0.3015\n",
      "Epoch 123/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2849 - val_loss: 0.2886\n",
      "Epoch 124/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2843 - val_loss: 0.2955\n",
      "Epoch 125/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2874 - val_loss: 0.2952\n",
      "Epoch 126/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2854 - val_loss: 0.3001\n",
      "Epoch 127/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2844 - val_loss: 0.2891\n",
      "Epoch 128/2000\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.2847 - val_loss: 0.3054\n",
      "Epoch 129/2000\n",
      "26/26 [==============================] - 6s 219ms/step - loss: 0.2857 - val_loss: 0.2913\n",
      "Epoch 130/2000\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.2838 - val_loss: 0.2917\n",
      "Epoch 131/2000\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.2842 - val_loss: 0.2886\n",
      "Epoch 132/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2842 - val_loss: 0.2885\n",
      "Epoch 133/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2841 - val_loss: 0.2867\n",
      "Epoch 134/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2833 - val_loss: 0.2899\n",
      "Epoch 135/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2834 - val_loss: 0.2912\n",
      "Epoch 136/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2826 - val_loss: 0.2842\n",
      "Epoch 137/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2860 - val_loss: 0.2983\n",
      "Epoch 138/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2856 - val_loss: 0.2868\n",
      "Epoch 139/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2851 - val_loss: 0.2866\n",
      "Epoch 140/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.2842 - val_loss: 0.2870\n",
      "Epoch 141/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2846 - val_loss: 0.2892\n",
      "Epoch 142/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2844 - val_loss: 0.2856\n",
      "Epoch 143/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2825 - val_loss: 0.2885\n",
      "Epoch 144/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2824 - val_loss: 0.2875\n",
      "Epoch 145/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2836 - val_loss: 0.2884\n",
      "Epoch 146/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2825 - val_loss: 0.2854\n",
      "Epoch 147/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2839 - val_loss: 0.2907\n",
      "Epoch 148/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2830 - val_loss: 0.2841\n",
      "Epoch 149/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2825 - val_loss: 0.2864\n",
      "Epoch 150/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2827 - val_loss: 0.2899\n",
      "Epoch 151/2000\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.2846 - val_loss: 0.2886\n",
      "Epoch 152/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2827 - val_loss: 0.2908\n",
      "Epoch 153/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2830 - val_loss: 0.2909\n",
      "Epoch 154/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2811 - val_loss: 0.2922\n",
      "Epoch 155/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2824 - val_loss: 0.2945\n",
      "Epoch 156/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2836 - val_loss: 0.2854\n",
      "Epoch 157/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2818 - val_loss: 0.3186\n",
      "Epoch 158/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2842 - val_loss: 0.2955\n",
      "Epoch 159/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2814 - val_loss: 0.2914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2813 - val_loss: 0.2891\n",
      "Epoch 161/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2817 - val_loss: 0.2881\n",
      "Epoch 162/2000\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.2812 - val_loss: 0.2884\n",
      "Epoch 163/2000\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.2798 - val_loss: 0.2823\n",
      "Epoch 164/2000\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.2824 - val_loss: 0.2958\n",
      "Epoch 165/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2837 - val_loss: 0.2855\n",
      "Epoch 166/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2813 - val_loss: 0.2918\n",
      "Epoch 167/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2818 - val_loss: 0.2927\n",
      "Epoch 168/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2809 - val_loss: 0.2870\n",
      "Epoch 169/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2795 - val_loss: 0.2904\n",
      "Epoch 170/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2811 - val_loss: 0.2966\n",
      "Epoch 171/2000\n",
      "26/26 [==============================] - 6s 242ms/step - loss: 0.2818 - val_loss: 0.2830\n",
      "Epoch 172/2000\n",
      "26/26 [==============================] - 6s 230ms/step - loss: 0.2795 - val_loss: 0.2883\n",
      "Epoch 173/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2802 - val_loss: 0.2921\n",
      "Epoch 174/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2797 - val_loss: 0.2851\n",
      "Epoch 175/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2801 - val_loss: 0.2859\n",
      "Epoch 176/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2803 - val_loss: 0.2819\n",
      "Epoch 177/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2798 - val_loss: 0.2897\n",
      "Epoch 178/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2799 - val_loss: 0.2826\n",
      "Epoch 179/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2819 - val_loss: 0.2886\n",
      "Epoch 180/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2799 - val_loss: 0.2871\n",
      "Epoch 181/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2786 - val_loss: 0.2848\n",
      "Epoch 182/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2807 - val_loss: 0.2834\n",
      "Epoch 183/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2802 - val_loss: 0.2835\n",
      "Epoch 184/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2798 - val_loss: 0.2884\n",
      "Epoch 185/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2806 - val_loss: 0.2912\n",
      "Epoch 186/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2803 - val_loss: 0.2845\n",
      "Epoch 187/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2785 - val_loss: 0.2858\n",
      "Epoch 188/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2791 - val_loss: 0.2805\n",
      "Epoch 189/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2834 - val_loss: 0.2818\n",
      "Epoch 190/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2797 - val_loss: 0.2883\n",
      "Epoch 191/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2795 - val_loss: 0.2905\n",
      "Epoch 192/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2779 - val_loss: 0.2854\n",
      "Epoch 193/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2779 - val_loss: 0.2868\n",
      "Epoch 194/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2826 - val_loss: 0.2984\n",
      "Epoch 195/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2797 - val_loss: 0.2837\n",
      "Epoch 196/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2812 - val_loss: 0.2832\n",
      "Epoch 197/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2799 - val_loss: 0.2824\n",
      "Epoch 198/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2788 - val_loss: 0.2854\n",
      "Epoch 199/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2798 - val_loss: 0.2819\n",
      "Epoch 200/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2810 - val_loss: 0.2871\n",
      "Epoch 201/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2785 - val_loss: 0.2860\n",
      "Epoch 202/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2783 - val_loss: 0.2875\n",
      "Epoch 203/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2772 - val_loss: 0.2906\n",
      "Epoch 204/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2787 - val_loss: 0.2845\n",
      "Epoch 205/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2768 - val_loss: 0.2842\n",
      "Epoch 206/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2775 - val_loss: 0.2812\n",
      "Epoch 207/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2775 - val_loss: 0.2838\n",
      "Epoch 208/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2772 - val_loss: 0.2868\n",
      "Epoch 209/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2778 - val_loss: 0.2828\n",
      "Epoch 210/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2771 - val_loss: 0.2842\n",
      "Epoch 211/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2786 - val_loss: 0.2862\n",
      "Epoch 212/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2782 - val_loss: 0.2839\n",
      "Epoch 213/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.2765 - val_loss: 0.2870\n",
      "Epoch 214/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2774 - val_loss: 0.2849\n",
      "Epoch 215/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.2773 - val_loss: 0.2823\n",
      "Epoch 216/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2766 - val_loss: 0.2843\n",
      "Epoch 217/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2779 - val_loss: 0.2857\n",
      "Epoch 218/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2771 - val_loss: 0.2814\n",
      "Epoch 219/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2773 - val_loss: 0.2830\n",
      "Epoch 220/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2791 - val_loss: 0.2826\n",
      "Epoch 221/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2792 - val_loss: 0.2834\n",
      "Epoch 222/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2767 - val_loss: 0.2804\n",
      "Epoch 223/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2789 - val_loss: 0.2877\n",
      "Epoch 224/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2766 - val_loss: 0.2846\n",
      "Epoch 225/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2771 - val_loss: 0.2806\n",
      "Epoch 226/2000\n",
      "26/26 [==============================] - 6s 238ms/step - loss: 0.2790 - val_loss: 0.2811\n",
      "Epoch 227/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2786 - val_loss: 0.2841\n",
      "Epoch 228/2000\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.2773 - val_loss: 0.2828\n",
      "Epoch 229/2000\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.2771 - val_loss: 0.2925\n",
      "Epoch 230/2000\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.2759 - val_loss: 0.2837\n",
      "Epoch 231/2000\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.2751 - val_loss: 0.2811\n",
      "Epoch 232/2000\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.2746 - val_loss: 0.2773\n",
      "Epoch 233/2000\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.2750 - val_loss: 0.2800\n",
      "Epoch 234/2000\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.2772 - val_loss: 0.2784\n",
      "Epoch 235/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2749 - val_loss: 0.2993\n",
      "Epoch 236/2000\n",
      "26/26 [==============================] - 6s 245ms/step - loss: 0.2783 - val_loss: 0.2804\n",
      "Epoch 237/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2779 - val_loss: 0.2801\n",
      "Epoch 238/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2748 - val_loss: 0.2782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2756 - val_loss: 0.2786\n",
      "Epoch 240/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2755 - val_loss: 0.2790\n",
      "Epoch 241/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2771 - val_loss: 0.3154\n",
      "Epoch 242/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2765 - val_loss: 0.2797\n",
      "Epoch 243/2000\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.2758 - val_loss: 0.2771\n",
      "Epoch 244/2000\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.2747 - val_loss: 0.2814\n",
      "Epoch 245/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2753 - val_loss: 0.2787\n",
      "Epoch 246/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2757 - val_loss: 0.2802\n",
      "Epoch 247/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2758 - val_loss: 0.2777\n",
      "Epoch 248/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2739 - val_loss: 0.2790\n",
      "Epoch 249/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2748 - val_loss: 0.2791\n",
      "Epoch 250/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2746 - val_loss: 0.2773\n",
      "Epoch 251/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2743 - val_loss: 0.2788\n",
      "Epoch 252/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2753 - val_loss: 0.2779\n",
      "Epoch 253/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2755 - val_loss: 0.2799\n",
      "Epoch 254/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2775 - val_loss: 0.2785\n",
      "Epoch 255/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2754 - val_loss: 0.2788\n",
      "Epoch 256/2000\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.2738 - val_loss: 0.2778\n",
      "Epoch 257/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2739 - val_loss: 0.2952\n",
      "Epoch 258/2000\n",
      "26/26 [==============================] - 7s 260ms/step - loss: 0.2750 - val_loss: 0.2770\n",
      "Epoch 259/2000\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.2746 - val_loss: 0.2790\n",
      "Epoch 260/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2741 - val_loss: 0.2789\n",
      "Epoch 261/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2746 - val_loss: 0.2770\n",
      "Epoch 262/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2749 - val_loss: 0.2766\n",
      "Epoch 263/2000\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.2730 - val_loss: 0.2766\n",
      "Epoch 264/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2767 - val_loss: 0.2804\n",
      "Epoch 265/2000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2762 - val_loss: 0.2896\n",
      "Epoch 266/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2747 - val_loss: 0.2773\n",
      "Epoch 267/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2739 - val_loss: 0.2776\n",
      "Epoch 268/2000\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.2753 - val_loss: 0.2801\n",
      "Epoch 269/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2726 - val_loss: 0.2786\n",
      "Epoch 270/2000\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 0.2725 - val_loss: 0.2762\n",
      "Epoch 271/2000\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.2729 - val_loss: 0.2790\n",
      "Epoch 272/2000\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.2756 - val_loss: 0.2780\n",
      "Epoch 273/2000\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.2721 - val_loss: 0.2782\n",
      "Epoch 274/2000\n",
      "26/26 [==============================] - 6s 230ms/step - loss: 0.2725 - val_loss: 0.2779\n",
      "Epoch 275/2000\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.2723 - val_loss: 0.2777\n",
      "Epoch 276/2000\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.2720 - val_loss: 0.2742\n",
      "Epoch 277/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2737 - val_loss: 0.2795\n",
      "Epoch 278/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2735 - val_loss: 0.2764\n",
      "Epoch 279/2000\n",
      "26/26 [==============================] - 6s 224ms/step - loss: 0.2729 - val_loss: 0.2767\n",
      "Epoch 280/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2717 - val_loss: 0.2753\n",
      "Epoch 281/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2718 - val_loss: 0.2775\n",
      "Epoch 282/2000\n",
      "26/26 [==============================] - 6s 230ms/step - loss: 0.2717 - val_loss: 0.2755\n",
      "Epoch 283/2000\n",
      "26/26 [==============================] - 6s 232ms/step - loss: 0.2712 - val_loss: 0.2735\n",
      "Epoch 284/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2728 - val_loss: 0.2789\n",
      "Epoch 285/2000\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.2731 - val_loss: 0.2773\n",
      "Epoch 286/2000\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.2718 - val_loss: 0.2766\n",
      "Epoch 287/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2977 - val_loss: 0.9126\n",
      "Epoch 288/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2891 - val_loss: 0.5072\n",
      "Epoch 289/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2799 - val_loss: 0.3886\n",
      "Epoch 290/2000\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.2788 - val_loss: 0.3068\n",
      "Epoch 291/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2766 - val_loss: 0.2992\n",
      "Epoch 292/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2761 - val_loss: 0.3029\n",
      "Epoch 293/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2780 - val_loss: 0.2834\n",
      "Epoch 294/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2766 - val_loss: 0.2780\n",
      "Epoch 295/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2742 - val_loss: 0.2854\n",
      "Epoch 296/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2759 - val_loss: 0.2903\n",
      "Epoch 297/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2762 - val_loss: 0.2765\n",
      "Epoch 298/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2742 - val_loss: 0.2820\n",
      "Epoch 299/2000\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.2751 - val_loss: 0.2775\n",
      "Epoch 300/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2747 - val_loss: 0.2776\n",
      "Epoch 301/2000\n",
      "26/26 [==============================] - 7s 258ms/step - loss: 0.2769 - val_loss: 0.2783\n",
      "Epoch 302/2000\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.2738 - val_loss: 0.2879\n",
      "Epoch 303/2000\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.2726 - val_loss: 0.2790\n",
      "Epoch 304/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2735 - val_loss: 0.2818\n",
      "Epoch 305/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2733 - val_loss: 0.2767\n",
      "Epoch 306/2000\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.2724 - val_loss: 0.2779\n",
      "Epoch 307/2000\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.2725 - val_loss: 0.2837\n",
      "Epoch 308/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2726 - val_loss: 0.2823\n",
      "Epoch 309/2000\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.2712 - val_loss: 0.2772\n",
      "Epoch 310/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2712 - val_loss: 0.2808\n",
      "Epoch 311/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2717 - val_loss: 0.2836\n",
      "Epoch 312/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2717 - val_loss: 0.2743\n",
      "Epoch 313/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2737 - val_loss: 0.2767\n",
      "Epoch 314/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2714 - val_loss: 0.2754\n",
      "Epoch 315/2000\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.2747 - val_loss: 0.2772\n",
      "Epoch 316/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2726 - val_loss: 0.2802\n",
      "Epoch 317/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2729 - val_loss: 0.2863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/2000\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.2722 - val_loss: 0.2798\n",
      "Epoch 319/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2726 - val_loss: 0.2755\n",
      "Epoch 320/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2736 - val_loss: 0.2862\n",
      "Epoch 321/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2728 - val_loss: 0.2831\n",
      "Epoch 322/2000\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.2709 - val_loss: 0.2939\n",
      "Epoch 323/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2747 - val_loss: 0.2765\n",
      "Epoch 324/2000\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.2735 - val_loss: 0.2783\n",
      "Epoch 325/2000\n",
      "26/26 [==============================] - 6s 244ms/step - loss: 0.2759 - val_loss: 0.2788\n",
      "Epoch 326/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2714 - val_loss: 0.2766\n",
      "Epoch 327/2000\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.2702 - val_loss: 0.2769\n",
      "Epoch 328/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2734 - val_loss: 0.2967\n",
      "Epoch 329/2000\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.2719 - val_loss: 0.2766\n",
      "Epoch 330/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2707 - val_loss: 0.2777\n",
      "Epoch 331/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2707 - val_loss: 0.2756\n",
      "Epoch 332/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2706 - val_loss: 0.2825\n",
      "Epoch 333/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2716 - val_loss: 0.2750\n",
      "Epoch 00333: early stopping\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"tensorflow_addonshistory = model.fit(\\n    X_train_preproc,\\n    y_train.reshape(-1, 1),\\n    epochs=2000,\\n    batch_size=1024,\\n    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\\n    verbose=1,\\n    callbacks=[EarlyStopping(monitor=\\\"val_loss\\\", patience=50, verbose=1)],\\n)\";\n",
       "                var nbb_formatted_code = \"tensorflow_addonshistory = model.fit(\\n    X_train_preproc,\\n    y_train.reshape(-1, 1),\\n    epochs=2000,\\n    batch_size=1024,\\n    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\\n    verbose=1,\\n    callbacks=[EarlyStopping(monitor=\\\"val_loss\\\", patience=50, verbose=1)],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    X_train_preproc,\n",
    "    y_train.reshape(-1, 1),\n",
    "    epochs=2000,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=100, verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.719810Z",
     "start_time": "2020-05-25T20:59:43.864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"plot_history(tensorflow_addonshistory)\";\n",
       "                var nbb_formatted_code = \"plot_history(tensorflow_addonshistory)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.720685Z",
     "start_time": "2020-05-25T20:59:43.865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347420166297309"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 114;\n",
       "                var nbb_unformatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_formatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_auc = roc_auc_score(\n",
    "    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\n",
    ")\n",
    "model_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.722364Z",
     "start_time": "2020-05-25T20:59:43.867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262939626480025"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 115;\n",
       "                var nbb_unformatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_formatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_auc = roc_auc_score(\n",
    "    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\n",
    ")\n",
    "model_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid 0.9282381974389771 test 0.9262939626480025 conv_dim=[64], lconv_dim=[128, 64, 32] patience 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"SAMPLE_NB = 1000\";\n",
       "                var nbb_formatted_code = \"SAMPLE_NB = 1000\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_NB = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"sample = X_valid_preproc[:SAMPLE]\";\n",
       "                var nbb_formatted_code = \"sample = X_valid_preproc[:SAMPLE]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = X_valid_preproc[:SAMPLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 81;\n",
       "                var nbb_unformatted_code = \"model_pred = model.predict(sample)\\nmodel_pred.shape\";\n",
       "                var nbb_formatted_code = \"model_pred = model.predict(sample)\\nmodel_pred.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pred = model.predict(sample)\n",
    "model_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 82;\n",
       "                var nbb_unformatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])\";\n",
       "                var nbb_formatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"new_model_pred, feature_inter = new_model.predict(sample)\";\n",
       "                var nbb_formatted_code = \"new_model_pred, feature_inter = new_model.predict(sample)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_pred, feature_inter = new_model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"assert np.all(model_pred == new_model_pred)\";\n",
       "                var nbb_formatted_code = \"assert np.all(model_pred == new_model_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert np.all(model_pred == new_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14, 32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"feature_inter.shape\";\n",
       "                var nbb_formatted_code = \"feature_inter.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"for idx in range(sample.shape[1]):\\n    one_col = np.zeros(sample.shape)\\n    one_col[:, idx] = sample[:, idx]\\n    _, feature_inter_one_col = new_model.predict(one_col)\\n    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\n    assert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_formatted_code = \"for idx in range(sample.shape[1]):\\n    one_col = np.zeros(sample.shape)\\n    one_col[:, idx] = sample[:, idx]\\n    _, feature_inter_one_col = new_model.predict(one_col)\\n    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\n    assert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(sample.shape[1]):\n",
    "    one_col = np.zeros(sample.shape)\n",
    "    one_col[:, idx] = sample[:, idx]\n",
    "    _, feature_inter_one_col = new_model.predict(one_col)\n",
    "    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\n",
    "    assert np.sum(feature_inter_one_col - feature_inter) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 90;\n",
       "                var nbb_unformatted_code = \"idx = 0\\none_col = np.zeros(sample.shape)\\none_col[:, idx] = sample[:, idx]\\n_, feature_inter_one_col = new_model.predict(one_col)\\nassert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\nassert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_formatted_code = \"idx = 0\\none_col = np.zeros(sample.shape)\\none_col[:, idx] = sample[:, idx]\\n_, feature_inter_one_col = new_model.predict(one_col)\\nassert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\nassert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "one_col = np.zeros(sample.shape)\n",
    "one_col[:, idx] = sample[:, idx]\n",
    "_, feature_inter_one_col = new_model.predict(one_col)\n",
    "assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\n",
    "assert np.sum(feature_inter_one_col - feature_inter) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 92;\n",
       "                var nbb_unformatted_code = \"feature_inter_one_col[:, 0, :].shape\";\n",
       "                var nbb_formatted_code = \"feature_inter_one_col[:, 0, :].shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_inter_one_col[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fda5c2f76d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 94;\n",
       "                var nbb_unformatted_code = \"new_model.layers[-1]\";\n",
       "                var nbb_formatted_code = \"new_model.layers[-1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 102;\n",
       "                var nbb_unformatted_code = \"model.get_weights()[-2].shape\";\n",
       "                var nbb_formatted_code = \"model.get_weights()[-2].shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.get_weights()[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 123;\n",
       "                var nbb_unformatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])\";\n",
       "                var nbb_formatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 9.54 s, total: 21.9 s\n",
      "Wall time: 6.14 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 124;\n",
       "                var nbb_unformatted_code = \"%%time\\n_, new_train_logistic = new_model.predict(X_train_preproc)\\n_, new_valid_logistic = new_model.predict(X_valid_preproc)\\n_, new_test_logistic = new_model.predict(X_test_preproc)\";\n",
       "                var nbb_formatted_code = \"%%time\\n_, new_train_logistic = new_model.predict(X_train_preproc)\\n_, new_valid_logistic = new_model.predict(X_valid_preproc)\\n_, new_test_logistic = new_model.predict(X_test_preproc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "_, new_train_logistic = new_model.predict(X_train_preproc)\n",
    "_, new_valid_logistic = new_model.predict(X_valid_preproc)\n",
    "_, new_test_logistic = new_model.predict(X_test_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 136;\n",
       "                var nbb_unformatted_code = \"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\";\n",
       "                var nbb_formatted_code = \"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 126;\n",
       "                var nbb_unformatted_code = \"lreg = LogisticRegression(max_iter=200, n_jobs=-1)\";\n",
       "                var nbb_formatted_code = \"lreg = LogisticRegression(max_iter=200, n_jobs=-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg = LogisticRegression(max_iter=200, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26108, 448)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 127;\n",
       "                var nbb_unformatted_code = \"new_train_logistic.shape\";\n",
       "                var nbb_formatted_code = \"new_train_logistic.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_train_logistic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, n_jobs=-1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 129;\n",
       "                var nbb_unformatted_code = \"lreg.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"lreg.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg.fit(new_train_logistic, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9331454088086971"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 134;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264309103810188"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 135;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 141;\n",
       "                var nbb_unformatted_code = \"lreg_cv = LogisticRegressionCV(Cs=100, max_iter=2000, n_jobs=-1, cv=10, random_state=0)\";\n",
       "                var nbb_formatted_code = \"lreg_cv = LogisticRegressionCV(Cs=100, max_iter=2000, n_jobs=-1, cv=10, random_state=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg_cv = LogisticRegressionCV(Cs=20, max_iter=2000, n_jobs=-1, cv=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-a868486caa11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlreg_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_logistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1897\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                       )\n\u001b[0;32m-> 1899\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m             for l1_ratio in l1_ratios_)\n",
      "\u001b[0;32m/work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 142;\n",
       "                var nbb_unformatted_code = \"lreg_cv.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"lreg_cv.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg_cv.fit(new_train_logistic, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_valid, y_score=lreg_cv.predict_proba(new_valid_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_test, y_score=lreg_cv.predict_proba(new_test_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
