{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:43.941660Z",
     "start_time": "2020-05-25T20:59:43.833639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:44.433824Z",
     "start_time": "2020-05-25T20:59:43.943368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import os\\nfrom pathlib import Path\\n\\nfrom requests import get\\nimport pandas as pd\\nimport numpy as np\\n\\nnp.random.seed(0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import roc_auc_score\\n\\nimport logging\\n\\nlogging.basicConfig(level=logging.WARN)\";\n",
       "                var nbb_formatted_code = \"import os\\nfrom pathlib import Path\\n\\nfrom requests import get\\nimport pandas as pd\\nimport numpy as np\\n\\nnp.random.seed(0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import roc_auc_score\\n\\nimport logging\\n\\nlogging.basicConfig(level=logging.WARN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.767278Z",
     "start_time": "2020-05-25T20:59:44.435849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from tensorflow.keras import Model, Input\\nfrom tensorflow.keras.layers import (\\n    Conv1D,\\n    SpatialDropout1D,\\n    LocallyConnected1D,\\n    Dense,\\n    Reshape,\\n    MaxPooling1D,\\n    BatchNormalization,\\n    Activation,\\n    LayerNormalization,\\n)\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nfrom tensorflow.keras.utils import to_categorical\\n\\nfrom tensorflow_addons.activations import mish\\nfrom tensorflow_addons.optimizers import RectifiedAdam, Lookahead\\nfrom tensorflow_addons.layers import WeightNormalization\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n\\nfrom itertools import repeat\\nfrom concurrent.futures import ProcessPoolExecutor as PoolExecutor\\n\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.pyplot import imshow\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"from tensorflow.keras import Model, Input\\nfrom tensorflow.keras.layers import (\\n    Conv1D,\\n    SpatialDropout1D,\\n    LocallyConnected1D,\\n    Dense,\\n    Reshape,\\n    MaxPooling1D,\\n    BatchNormalization,\\n    Activation,\\n    LayerNormalization,\\n)\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nfrom tensorflow.keras.utils import to_categorical\\n\\nfrom tensorflow_addons.activations import mish\\nfrom tensorflow_addons.optimizers import RectifiedAdam, Lookahead\\nfrom tensorflow_addons.layers import WeightNormalization\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n\\nfrom itertools import repeat\\nfrom concurrent.futures import ProcessPoolExecutor as PoolExecutor\\n\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.pyplot import imshow\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    SpatialDropout1D,\n",
    "    LocallyConnected1D,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    LayerNormalization,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow_addons.activations import mish\n",
    "from tensorflow_addons.optimizers import RectifiedAdam, Lookahead\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from itertools import repeat\n",
    "from concurrent.futures import ProcessPoolExecutor as PoolExecutor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import tensorflow_addons as tfa\\n\\ntfa.options.TF_ADDONS_PY_OPS = True\";\n",
       "                var nbb_formatted_code = \"import tensorflow_addons as tfa\\n\\ntfa.options.TF_ADDONS_PY_OPS = True\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "tfa.options.TF_ADDONS_PY_OPS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.781039Z",
     "start_time": "2020-05-25T20:59:45.769170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def word_to_np_array(word, cut_length):\\n    result = np.zeros(cut_length, dtype=\\\"uint8\\\")\\n    for i, letter in enumerate(word[:cut_length]):\\n        result[i] = ord(letter)\\n    return result\";\n",
       "                var nbb_formatted_code = \"def word_to_np_array(word, cut_length):\\n    result = np.zeros(cut_length, dtype=\\\"uint8\\\")\\n    for i, letter in enumerate(word[:cut_length]):\\n        result[i] = ord(letter)\\n    return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def word_to_np_array(word, cut_length):\n",
    "    result = np.zeros(cut_length, dtype=\"uint8\")\n",
    "    for i, letter in enumerate(word[:cut_length]):\n",
    "        result[i] = ord(letter)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:45.893504Z",
     "start_time": "2020-05-25T20:59:45.782485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def line_to_img(line, cut_length):\\n    result = np.zeros((line.shape[0], cut_length), dtype=\\\"uint8\\\")\\n    for i in range(line.shape[0]):\\n        result[i] = word_to_np_array(line[i], cut_length)\\n    return result\";\n",
       "                var nbb_formatted_code = \"def line_to_img(line, cut_length):\\n    result = np.zeros((line.shape[0], cut_length), dtype=\\\"uint8\\\")\\n    for i in range(line.shape[0]):\\n        result[i] = word_to_np_array(line[i], cut_length)\\n    return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def line_to_img(line, cut_length):\n",
    "    result = np.zeros((line.shape[0], cut_length), dtype=\"uint8\")\n",
    "    for i in range(line.shape[0]):\n",
    "        result[i] = word_to_np_array(line[i], cut_length)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.016629Z",
     "start_time": "2020-05-25T20:59:45.895831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def do_parallel_numpy(map_func, iter_params, constant_params=None):\\n    repeated_params = (\\n        [] if constant_params is None else list(map(repeat, constant_params))\\n    )\\n    results = None\\n    with PoolExecutor() as executor:\\n        results = np.stack(\\n            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\\n        )\\n    return results\";\n",
       "                var nbb_formatted_code = \"def do_parallel_numpy(map_func, iter_params, constant_params=None):\\n    repeated_params = (\\n        [] if constant_params is None else list(map(repeat, constant_params))\\n    )\\n    results = None\\n    with PoolExecutor() as executor:\\n        results = np.stack(\\n            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\\n        )\\n    return results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_parallel_numpy(map_func, iter_params, constant_params=None):\n",
    "    repeated_params = (\n",
    "        [] if constant_params is None else list(map(repeat, constant_params))\n",
    "    )\n",
    "    results = None\n",
    "    with PoolExecutor() as executor:\n",
    "        results = np.stack(\n",
    "            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.106802Z",
     "start_time": "2020-05-25T20:59:46.020842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def download(url, out, force=False, verify=True):\\n    out.parent.mkdir(parents=True, exist_ok=True)\\n    if force and out.exists():\\n        print(f\\\"Removing file at {str(out)}\\\")\\n        out.unlink()\\n\\n    if out.exists():\\n        print(\\\"File already exists.\\\")\\n        return\\n    print(f\\\"Downloading {url} at {str(out)} ...\\\")\\n    # open in binary mode\\n    with out.open(mode=\\\"wb\\\") as file:\\n        # get request\\n        response = get(url, verify=verify)\\n        for chunk in response.iter_content(100000):\\n            # write to file\\n            file.write(chunk)\";\n",
       "                var nbb_formatted_code = \"def download(url, out, force=False, verify=True):\\n    out.parent.mkdir(parents=True, exist_ok=True)\\n    if force and out.exists():\\n        print(f\\\"Removing file at {str(out)}\\\")\\n        out.unlink()\\n\\n    if out.exists():\\n        print(\\\"File already exists.\\\")\\n        return\\n    print(f\\\"Downloading {url} at {str(out)} ...\\\")\\n    # open in binary mode\\n    with out.open(mode=\\\"wb\\\") as file:\\n        # get request\\n        response = get(url, verify=verify)\\n        for chunk in response.iter_content(100000):\\n            # write to file\\n            file.write(chunk)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download(url, out, force=False, verify=True):\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if force and out.exists():\n",
    "        print(f\"Removing file at {str(out)}\")\n",
    "        out.unlink()\n",
    "\n",
    "    if out.exists():\n",
    "        print(\"File already exists.\")\n",
    "        return\n",
    "    print(f\"Downloading {url} at {str(out)} ...\")\n",
    "    # open in binary mode\n",
    "    with out.open(mode=\"wb\") as file:\n",
    "        # get request\n",
    "        response = get(url, verify=verify)\n",
    "        for chunk in response.iter_content(100000):\n",
    "            # write to file\n",
    "            file.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.210035Z",
     "start_time": "2020-05-25T20:59:46.110562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def plot_history(history):\\n    loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" not in s]\\n    val_loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" in s]\\n    acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" not in s]\\n    val_acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" in s]\\n\\n    if len(loss_list) == 0:\\n        print(\\\"Loss is missing in history\\\")\\n        return\\n\\n    ## As loss always exists\\n    epochs = range(1, len(history.history[loss_list[0]]) + 1)\\n\\n    ## Loss\\n    plt.figure(1)\\n    for l in loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"b\\\",\\n            label=\\\"Training loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n    for l in val_loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"g\\\",\\n            label=\\\"Validation loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n\\n    plt.title(\\\"Loss\\\")\\n    plt.xlabel(\\\"Epochs\\\")\\n    plt.ylabel(\\\"Loss\\\")\\n    plt.legend()\\n\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def plot_history(history):\\n    loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" not in s]\\n    val_loss_list = [s for s in history.history.keys() if \\\"loss\\\" in s and \\\"val\\\" in s]\\n    acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" not in s]\\n    val_acc_list = [s for s in history.history.keys() if \\\"AUC\\\" in s and \\\"val\\\" in s]\\n\\n    if len(loss_list) == 0:\\n        print(\\\"Loss is missing in history\\\")\\n        return\\n\\n    ## As loss always exists\\n    epochs = range(1, len(history.history[loss_list[0]]) + 1)\\n\\n    ## Loss\\n    plt.figure(1)\\n    for l in loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"b\\\",\\n            label=\\\"Training loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n    for l in val_loss_list:\\n        plt.plot(\\n            epochs,\\n            history.history[l],\\n            \\\"g\\\",\\n            label=\\\"Validation loss (\\\"\\n            + str(str(format(history.history[l][-1], \\\".5f\\\")) + \\\")\\\"),\\n        )\\n\\n    plt.title(\\\"Loss\\\")\\n    plt.xlabel(\\\"Epochs\\\")\\n    plt.ylabel(\\\"Loss\\\")\\n    plt.legend()\\n\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if \"loss\" in s and \"val\" not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if \"loss\" in s and \"val\" in s]\n",
    "    acc_list = [s for s in history.history.keys() if \"AUC\" in s and \"val\" not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if \"AUC\" in s and \"val\" in s]\n",
    "\n",
    "    if len(loss_list) == 0:\n",
    "        print(\"Loss is missing in history\")\n",
    "        return\n",
    "\n",
    "    ## As loss always exists\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "\n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(\n",
    "            epochs,\n",
    "            history.history[l],\n",
    "            \"b\",\n",
    "            label=\"Training loss (\"\n",
    "            + str(str(format(history.history[l][-1], \".5f\")) + \")\"),\n",
    "        )\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(\n",
    "            epochs,\n",
    "            history.history[l],\n",
    "            \"g\",\n",
    "            label=\"Validation loss (\"\n",
    "            + str(str(format(history.history[l][-1], \".5f\")) + \")\"),\n",
    "        )\n",
    "\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.276902Z",
     "start_time": "2020-05-25T20:59:46.212058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "File already exists.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"url = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\\"\\nurl_test = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\\\"\\n\\ndataset_name = \\\"census-income\\\"\\nout = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\".csv\\\")\\nout_test = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\"_test.csv\\\")\\n\\ndownload(url, out, force=False)\\ndownload(url_test, out_test, force=False)\";\n",
       "                var nbb_formatted_code = \"url = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\\"\\nurl_test = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\\\"\\n\\ndataset_name = \\\"census-income\\\"\\nout = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\".csv\\\")\\nout_test = Path(os.getcwd() + \\\"/data/\\\" + dataset_name + \\\"_test.csv\\\")\\n\\ndownload(url, out, force=False)\\ndownload(url_test, out_test, force=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "url_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "\n",
    "dataset_name = \"census-income\"\n",
    "out = Path(os.getcwd() + \"/data/\" + dataset_name + \".csv\")\n",
    "out_test = Path(os.getcwd() + \"/data/\" + dataset_name + \"_test.csv\")\n",
    "\n",
    "download(url, out, force=False)\n",
    "download(url_test, out_test, force=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.361578Z",
     "start_time": "2020-05-25T20:59:46.279187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"cols = [\\n    \\\"age\\\",\\n    \\\"workclass\\\",\\n    \\\"fnlwgt\\\",\\n    \\\"education\\\",\\n    \\\"education-num\\\",\\n    \\\"marital-status\\\",\\n    \\\"occupation\\\",\\n    \\\"relationship\\\",\\n    \\\"race\\\",\\n    \\\"sex\\\",\\n    \\\"capital-gain\\\",\\n    \\\"capital-loss\\\",\\n    \\\"hours-per-week\\\",\\n    \\\"native-country\\\",\\n    \\\"target\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"cols = [\\n    \\\"age\\\",\\n    \\\"workclass\\\",\\n    \\\"fnlwgt\\\",\\n    \\\"education\\\",\\n    \\\"education-num\\\",\\n    \\\"marital-status\\\",\\n    \\\"occupation\\\",\\n    \\\"relationship\\\",\\n    \\\"race\\\",\\n    \\\"sex\\\",\\n    \\\"capital-gain\\\",\\n    \\\"capital-loss\\\",\\n    \\\"hours-per-week\\\",\\n    \\\"native-country\\\",\\n    \\\"target\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"target\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.557825Z",
     "start_time": "2020-05-25T20:59:46.365361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"train = pd.read_csv(out, names=cols)\\ntest = pd.read_csv(out_test, names=cols, skiprows=2)\\ntarget = \\\"target\\\"\\n\\ntrain[target] = train[target].str.strip()\\n# Test has . in label, let's clean it\\ntest[target] = test[target].str.strip().str.strip(\\\".\\\")\";\n",
       "                var nbb_formatted_code = \"train = pd.read_csv(out, names=cols)\\ntest = pd.read_csv(out_test, names=cols, skiprows=2)\\ntarget = \\\"target\\\"\\n\\ntrain[target] = train[target].str.strip()\\n# Test has . in label, let's clean it\\ntest[target] = test[target].str.strip().str.strip(\\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(out, names=cols)\n",
    "test = pd.read_csv(out_test, names=cols, skiprows=2)\n",
    "target = \"target\"\n",
    "\n",
    "train[target] = train[target].str.strip()\n",
    "# Test has . in label, let's clean it\n",
    "test[target] = test[target].str.strip().str.strip(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.566032Z",
     "start_time": "2020-05-25T20:59:46.559340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"target_encoder = LabelEncoder()\";\n",
       "                var nbb_formatted_code = \"target_encoder = LabelEncoder()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.661768Z",
     "start_time": "2020-05-25T20:59:46.567593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\\ntest[target] = target_encoder.transform(test[target].values.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\\ntest[target] = target_encoder.transform(test[target].values.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[target] = target_encoder.fit_transform(train[target].values.reshape(-1))\n",
    "test[target] = target_encoder.transform(test[target].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:46.745241Z",
     "start_time": "2020-05-25T20:59:46.663423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hours-per-week',\n",
       " 'education-num',\n",
       " 'education',\n",
       " 'sex',\n",
       " 'relationship',\n",
       " 'age',\n",
       " 'capital-gain',\n",
       " 'occupation',\n",
       " 'workclass',\n",
       " 'marital-status',\n",
       " 'race',\n",
       " 'native-country',\n",
       " 'fnlwgt',\n",
       " 'capital-loss']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"used_columns = list(set(train.columns.tolist()) - set([target]) - set([\\\"Set\\\"]))\\nused_columns\";\n",
       "                var nbb_formatted_code = \"used_columns = list(set(train.columns.tolist()) - set([target]) - set([\\\"Set\\\"]))\\nused_columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "used_columns = list(set(train.columns.tolist()) - set([target]) - set([\"Set\"]))\n",
    "used_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.405604Z",
     "start_time": "2020-05-25T20:59:46.747053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"train[\\\"Set\\\"] = np.random.choice(\\n    [\\\"train\\\", \\\"valid\\\"], p=[0.8, 0.2], size=(train.shape[0],)\\n)\\n\\ntrain_indices = train[train.Set == \\\"train\\\"].index\\nvalid_indices = train[train.Set == \\\"valid\\\"].index\\n\\nX_train = np.char.strip(train[used_columns].values[train_indices].astype(\\\"str\\\"))\\nX_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\\\"str\\\"))\\n\\ny_train = train[target].values[train_indices]\\ny_valid = train[target].values[valid_indices]\\n\\n# Test here should be ignored for training, only purpose is benching with paper values\\nX_test = np.char.strip(test[used_columns].values.astype(\\\"str\\\"))\\ny_test = test[target].values\\n\\ndel train, test, train_indices, valid_indices\";\n",
       "                var nbb_formatted_code = \"train[\\\"Set\\\"] = np.random.choice(\\n    [\\\"train\\\", \\\"valid\\\"], p=[0.8, 0.2], size=(train.shape[0],)\\n)\\n\\ntrain_indices = train[train.Set == \\\"train\\\"].index\\nvalid_indices = train[train.Set == \\\"valid\\\"].index\\n\\nX_train = np.char.strip(train[used_columns].values[train_indices].astype(\\\"str\\\"))\\nX_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\\\"str\\\"))\\n\\ny_train = train[target].values[train_indices]\\ny_valid = train[target].values[valid_indices]\\n\\n# Test here should be ignored for training, only purpose is benching with paper values\\nX_test = np.char.strip(test[used_columns].values.astype(\\\"str\\\"))\\ny_test = test[target].values\\n\\ndel train, test, train_indices, valid_indices\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"Set\"] = np.random.choice(\n",
    "    [\"train\", \"valid\"], p=[0.8, 0.2], size=(train.shape[0],)\n",
    ")\n",
    "\n",
    "train_indices = train[train.Set == \"train\"].index\n",
    "valid_indices = train[train.Set == \"valid\"].index\n",
    "\n",
    "X_train = np.char.strip(train[used_columns].values[train_indices].astype(\"str\"))\n",
    "X_valid = np.char.strip(train[used_columns].values[valid_indices].astype(\"str\"))\n",
    "\n",
    "y_train = train[target].values[train_indices]\n",
    "y_valid = train[target].values[valid_indices]\n",
    "\n",
    "# Test here should be ignored for training, only purpose is benching with paper values\n",
    "X_test = np.char.strip(test[used_columns].values.astype(\"str\"))\n",
    "y_test = test[target].values\n",
    "\n",
    "del train, test, train_indices, valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.412417Z",
     "start_time": "2020-05-25T20:59:47.406951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26072, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"X_train.shape\";\n",
       "                var nbb_formatted_code = \"X_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.573456Z",
     "start_time": "2020-05-25T20:59:47.413649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"INPUT_DIM = X_train.shape[1]\\nNB_CHANNELS = np.vectorize(len)(X_train).max()\\nNB_CHANNELS\";\n",
       "                var nbb_formatted_code = \"INPUT_DIM = X_train.shape[1]\\nNB_CHANNELS = np.vectorize(len)(X_train).max()\\nNB_CHANNELS\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIM = X_train.shape[1]\n",
    "NB_CHANNELS = np.vectorize(len)(X_train).max()\n",
    "NB_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T20:59:47.616024Z",
     "start_time": "2020-05-25T20:59:47.574971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"line_to_img(X_train[0], 27).shape\";\n",
       "                var nbb_formatted_code = \"line_to_img(X_train[0], 27).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_to_img(X_train[0], 27).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.007709Z",
     "start_time": "2020-05-25T20:59:47.617541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\\nX_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\\nX_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])\";\n",
       "                var nbb_formatted_code = \"X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\\nX_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\\nX_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_preproc = do_parallel_numpy(line_to_img, [X_train], [NB_CHANNELS])\n",
    "X_valid_preproc = do_parallel_numpy(line_to_img, [X_valid], [NB_CHANNELS])\n",
    "X_test_preproc = do_parallel_numpy(line_to_img, [X_test], [NB_CHANNELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T19:22:09.609604Z",
     "start_time": "2020-05-25T19:22:09.602138Z"
    }
   },
   "source": [
    "Y_train_preproc = to_categorical(y_train)\n",
    "Y_valid_preproc = to_categorical(y_valid)\n",
    "Y_test_preproc = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.061348Z",
     "start_time": "2020-05-25T21:00:00.017086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\\n    activation = mish\\n    optimizer = Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\\n\\n    input_layer = Input(shape=(input_dim, nb_channels), name=\\\"input\\\")\\n    x_layer = input_layer\\n    for i, conv_layer in enumerate(conv_dim):\\n        name = f\\\"block_conv_{i}_\\\"\\n        x_layer = Conv1D(\\n            filters=conv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"conv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    for i, lconv_layer in enumerate(lconv_dim):\\n        name = f\\\"block_lconv_{i}_\\\"\\n        x_layer = LocallyConnected1D(\\n            filters=lconv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"lconv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\\n    x_layer = Reshape((input_dim * nb_filters,), name=\\\"reshape\\\")(x_layer)\\n    x_layer = Dense(1, activation=\\\"sigmoid\\\", name=\\\"output\\\")(x_layer)\\n\\n    model = Model(inputs=[input_layer], outputs=[x_layer], name=\\\"first_model\\\")\\n    model.compile(loss=\\\"binary_crossentropy\\\", optimizer=optimizer)\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\\n    activation = mish\\n    optimizer = Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\\n\\n    input_layer = Input(shape=(input_dim, nb_channels), name=\\\"input\\\")\\n    x_layer = input_layer\\n    for i, conv_layer in enumerate(conv_dim):\\n        name = f\\\"block_conv_{i}_\\\"\\n        x_layer = Conv1D(\\n            filters=conv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"conv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    for i, lconv_layer in enumerate(lconv_dim):\\n        name = f\\\"block_lconv_{i}_\\\"\\n        x_layer = LocallyConnected1D(\\n            filters=lconv_layer,\\n            padding=\\\"valid\\\",\\n            kernel_size=1,\\n            strides=1,\\n            name=name + \\\"lconv\\\",\\n            use_bias=False,\\n            activation=None,\\n        )(x_layer)\\n        x_layer = BatchNormalization(name=name + \\\"nb\\\")(x_layer)\\n        x_layer = Activation(activation, name=name + \\\"activation\\\")(x_layer)\\n\\n    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\\n    x_layer = Reshape((input_dim * nb_filters,), name=\\\"reshape\\\")(x_layer)\\n    x_layer = Dense(1, activation=\\\"sigmoid\\\", name=\\\"output\\\")(x_layer)\\n\\n    model = Model(inputs=[input_layer], outputs=[x_layer], name=\\\"first_model\\\")\\n    model.compile(loss=\\\"binary_crossentropy\\\", optimizer=optimizer)\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(input_dim, nb_channels, conv_dim=[], lconv_dim=[]):\n",
    "    activation = mish\n",
    "    optimizer = Lookahead(RectifiedAdam(1e-3), sync_period=6, slow_step_size=0.5)\n",
    "\n",
    "    input_layer = Input(shape=(input_dim, nb_channels), name=\"input\")\n",
    "    x_layer = input_layer\n",
    "    for i, conv_layer in enumerate(conv_dim):\n",
    "        name = f\"block_conv_{i}_\"\n",
    "        x_layer = Conv1D(\n",
    "            filters=conv_layer,\n",
    "            padding=\"valid\",\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            name=name + \"conv\",\n",
    "            use_bias=False,\n",
    "            activation=None,\n",
    "        )(x_layer)\n",
    "        x_layer = BatchNormalization(name=name + \"nb\")(x_layer)\n",
    "        x_layer = Activation(activation, name=name + \"activation\")(x_layer)\n",
    "\n",
    "    for i, lconv_layer in enumerate(lconv_dim):\n",
    "        name = f\"block_lconv_{i}_\"\n",
    "        x_layer = LocallyConnected1D(\n",
    "            filters=lconv_layer,\n",
    "            padding=\"valid\",\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            name=name + \"lconv\",\n",
    "            use_bias=False,\n",
    "            activation=None,\n",
    "        )(x_layer)\n",
    "        x_layer = BatchNormalization(name=name + \"nb\")(x_layer)\n",
    "        x_layer = Activation(activation, name=name + \"activation\")(x_layer)\n",
    "\n",
    "    nb_filters = lconv_dim[-1] if len(lconv_dim) > 0 else conv_dim[-1]\n",
    "    x_layer = Reshape((input_dim * nb_filters,), name=\"reshape\")(x_layer)\n",
    "    x_layer = Dense(1, activation=\"sigmoid\", name=\"output\")(x_layer)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x_layer], name=\"first_model\")\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.979562Z",
     "start_time": "2020-05-25T21:00:00.062758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])\";\n",
       "                var nbb_formatted_code = \"model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(INPUT_DIM, NB_CHANNELS, conv_dim=[64], lconv_dim=[128, 64, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:00.994383Z",
     "start_time": "2020-05-25T21:00:00.981768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"first_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 14, 26)]          0         \n",
      "_________________________________________________________________\n",
      "block_conv_0_conv (Conv1D)   (None, 14, 64)            1664      \n",
      "_________________________________________________________________\n",
      "block_conv_0_nb (BatchNormal (None, 14, 64)            256       \n",
      "_________________________________________________________________\n",
      "block_conv_0_activation (Act (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "block_lconv_0_lconv (Locally (None, 14, 128)           114688    \n",
      "_________________________________________________________________\n",
      "block_lconv_0_nb (BatchNorma (None, 14, 128)           512       \n",
      "_________________________________________________________________\n",
      "block_lconv_0_activation (Ac (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "block_lconv_1_lconv (Locally (None, 14, 64)            114688    \n",
      "_________________________________________________________________\n",
      "block_lconv_1_nb (BatchNorma (None, 14, 64)            256       \n",
      "_________________________________________________________________\n",
      "block_lconv_1_activation (Ac (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "block_lconv_2_lconv (Locally (None, 14, 32)            28672     \n",
      "_________________________________________________________________\n",
      "block_lconv_2_nb (BatchNorma (None, 14, 32)            128       \n",
      "_________________________________________________________________\n",
      "block_lconv_2_activation (Ac (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 261,313\n",
      "Trainable params: 260,737\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"model.summary()\";\n",
       "                var nbb_formatted_code = \"model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:01.114121Z",
     "start_time": "2020-05-25T21:00:00.997404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26072,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"y_train.shape\";\n",
       "                var nbb_formatted_code = \"y_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.717722Z",
     "start_time": "2020-05-25T21:00:01.118492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /work/.cache/poetry/thc-net-KQLMmzPP-py3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 6s 232ms/step - loss: 0.5426 - val_loss: 0.6850\n",
      "Epoch 2/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.3813 - val_loss: 0.6861\n",
      "Epoch 3/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.3558 - val_loss: 0.6881\n",
      "Epoch 4/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.3451 - val_loss: 0.6893\n",
      "Epoch 5/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.3415 - val_loss: 0.6888\n",
      "Epoch 6/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3392 - val_loss: 0.6885\n",
      "Epoch 7/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.3365 - val_loss: 0.6860\n",
      "Epoch 8/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3345 - val_loss: 0.6771\n",
      "Epoch 9/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.3345 - val_loss: 0.6625\n",
      "Epoch 10/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.3316 - val_loss: 0.6493\n",
      "Epoch 11/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3326 - val_loss: 0.5982\n",
      "Epoch 12/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3291 - val_loss: 0.5782\n",
      "Epoch 13/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3269 - val_loss: 0.5281\n",
      "Epoch 14/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.3273 - val_loss: 0.5342\n",
      "Epoch 15/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.3252 - val_loss: 0.4678\n",
      "Epoch 16/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3200 - val_loss: 0.4628\n",
      "Epoch 17/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3187 - val_loss: 0.4963\n",
      "Epoch 18/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.3172 - val_loss: 0.4016\n",
      "Epoch 19/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.3139 - val_loss: 0.4071\n",
      "Epoch 20/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.3117 - val_loss: 0.4728\n",
      "Epoch 21/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3114 - val_loss: 0.3818\n",
      "Epoch 22/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3102 - val_loss: 0.4004\n",
      "Epoch 23/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3071 - val_loss: 0.4492\n",
      "Epoch 24/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3078 - val_loss: 0.4028\n",
      "Epoch 25/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.3101 - val_loss: 0.3613\n",
      "Epoch 26/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3072 - val_loss: 0.4012\n",
      "Epoch 27/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.3057 - val_loss: 0.3565\n",
      "Epoch 28/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3044 - val_loss: 0.3286\n",
      "Epoch 29/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3059 - val_loss: 0.3435\n",
      "Epoch 30/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.3035 - val_loss: 0.3339\n",
      "Epoch 31/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3038 - val_loss: 0.3597\n",
      "Epoch 32/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.3036 - val_loss: 0.3353\n",
      "Epoch 33/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3016 - val_loss: 0.3387\n",
      "Epoch 34/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.3016 - val_loss: 0.3133\n",
      "Epoch 35/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.3063 - val_loss: 0.3133\n",
      "Epoch 36/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.3013 - val_loss: 0.3369\n",
      "Epoch 37/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.3030 - val_loss: 0.3184\n",
      "Epoch 38/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.3024 - val_loss: 0.3145\n",
      "Epoch 39/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.3002 - val_loss: 0.3242\n",
      "Epoch 40/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.3005 - val_loss: 0.3265\n",
      "Epoch 41/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.3014 - val_loss: 0.3293\n",
      "Epoch 42/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.3034 - val_loss: 0.3263\n",
      "Epoch 43/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.3018 - val_loss: 0.3034\n",
      "Epoch 44/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.3013 - val_loss: 0.3115\n",
      "Epoch 45/2000\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.3015 - val_loss: 0.3090\n",
      "Epoch 46/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2994 - val_loss: 0.3433\n",
      "Epoch 47/2000\n",
      "26/26 [==============================] - 6s 239ms/step - loss: 0.2987 - val_loss: 0.3093\n",
      "Epoch 48/2000\n",
      "26/26 [==============================] - 6s 238ms/step - loss: 0.3020 - val_loss: 0.3102\n",
      "Epoch 49/2000\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.3011 - val_loss: 0.3019\n",
      "Epoch 50/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.3004 - val_loss: 0.3400\n",
      "Epoch 51/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2986 - val_loss: 0.3100\n",
      "Epoch 52/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2972 - val_loss: 0.3153\n",
      "Epoch 53/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2980 - val_loss: 0.3013\n",
      "Epoch 54/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2979 - val_loss: 0.3130\n",
      "Epoch 55/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2979 - val_loss: 0.3017\n",
      "Epoch 56/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2978 - val_loss: 0.2966\n",
      "Epoch 57/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2981 - val_loss: 0.2984\n",
      "Epoch 58/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2972 - val_loss: 0.3108\n",
      "Epoch 59/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2976 - val_loss: 0.3046\n",
      "Epoch 60/2000\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.2985 - val_loss: 0.3062\n",
      "Epoch 61/2000\n",
      "26/26 [==============================] - 7s 264ms/step - loss: 0.2963 - val_loss: 0.3176\n",
      "Epoch 62/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2980 - val_loss: 0.3207\n",
      "Epoch 63/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2965 - val_loss: 0.3093\n",
      "Epoch 64/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2956 - val_loss: 0.3100\n",
      "Epoch 65/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2954 - val_loss: 0.3120\n",
      "Epoch 66/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2951 - val_loss: 0.3044\n",
      "Epoch 67/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2953 - val_loss: 0.3145\n",
      "Epoch 68/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2958 - val_loss: 0.2966\n",
      "Epoch 69/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2945 - val_loss: 0.3086\n",
      "Epoch 70/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2942 - val_loss: 0.3232\n",
      "Epoch 71/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2968 - val_loss: 0.2961\n",
      "Epoch 72/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2950 - val_loss: 0.3007\n",
      "Epoch 73/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2956 - val_loss: 0.2957\n",
      "Epoch 74/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2933 - val_loss: 0.2981\n",
      "Epoch 75/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2929 - val_loss: 0.2958\n",
      "Epoch 76/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2936 - val_loss: 0.3016\n",
      "Epoch 77/2000\n",
      "26/26 [==============================] - 6s 249ms/step - loss: 0.2937 - val_loss: 0.3256\n",
      "Epoch 78/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2944 - val_loss: 0.3000\n",
      "Epoch 79/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2942 - val_loss: 0.2978\n",
      "Epoch 80/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2929 - val_loss: 0.3084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2957 - val_loss: 0.3039\n",
      "Epoch 82/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2917 - val_loss: 0.3080\n",
      "Epoch 83/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2922 - val_loss: 0.3004\n",
      "Epoch 84/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2932 - val_loss: 0.2935\n",
      "Epoch 85/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2927 - val_loss: 0.2907\n",
      "Epoch 86/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2933 - val_loss: 0.3066\n",
      "Epoch 87/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2934 - val_loss: 0.2993\n",
      "Epoch 88/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2915 - val_loss: 0.3177\n",
      "Epoch 89/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2903 - val_loss: 0.2987\n",
      "Epoch 90/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2915 - val_loss: 0.2981\n",
      "Epoch 91/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2912 - val_loss: 0.2934\n",
      "Epoch 92/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2917 - val_loss: 0.2944\n",
      "Epoch 93/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2965 - val_loss: 0.2966\n",
      "Epoch 94/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2953 - val_loss: 0.2952\n",
      "Epoch 95/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2958 - val_loss: 0.2973\n",
      "Epoch 96/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2927 - val_loss: 0.3029\n",
      "Epoch 97/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2945 - val_loss: 0.3074\n",
      "Epoch 98/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2939 - val_loss: 0.2941\n",
      "Epoch 99/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2928 - val_loss: 0.2939\n",
      "Epoch 100/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2906 - val_loss: 0.2946\n",
      "Epoch 101/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2903 - val_loss: 0.3083\n",
      "Epoch 102/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2906 - val_loss: 0.2958\n",
      "Epoch 103/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2945 - val_loss: 0.2974\n",
      "Epoch 104/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2924 - val_loss: 0.3032\n",
      "Epoch 105/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2910 - val_loss: 0.2965\n",
      "Epoch 106/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2916 - val_loss: 0.2938\n",
      "Epoch 107/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2911 - val_loss: 0.2985\n",
      "Epoch 108/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2933 - val_loss: 0.2976\n",
      "Epoch 109/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2905 - val_loss: 0.2980\n",
      "Epoch 110/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2894 - val_loss: 0.3051\n",
      "Epoch 111/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2926 - val_loss: 0.2928\n",
      "Epoch 112/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2885 - val_loss: 0.2963\n",
      "Epoch 113/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2888 - val_loss: 0.3069\n",
      "Epoch 114/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2888 - val_loss: 0.3018\n",
      "Epoch 115/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2884 - val_loss: 0.2920\n",
      "Epoch 116/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2885 - val_loss: 0.2958\n",
      "Epoch 117/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2896 - val_loss: 0.2924\n",
      "Epoch 118/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2884 - val_loss: 0.2978\n",
      "Epoch 119/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2871 - val_loss: 0.2950\n",
      "Epoch 120/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2877 - val_loss: 0.2970\n",
      "Epoch 121/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2878 - val_loss: 0.2916\n",
      "Epoch 122/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2873 - val_loss: 0.3023\n",
      "Epoch 123/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2885 - val_loss: 0.2984\n",
      "Epoch 124/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2896 - val_loss: 0.3062\n",
      "Epoch 125/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2886 - val_loss: 0.3053\n",
      "Epoch 126/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2907 - val_loss: 0.2892\n",
      "Epoch 127/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2892 - val_loss: 0.3080\n",
      "Epoch 128/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2882 - val_loss: 0.2927\n",
      "Epoch 129/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2859 - val_loss: 0.2950\n",
      "Epoch 130/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2853 - val_loss: 0.3081\n",
      "Epoch 131/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2856 - val_loss: 0.2961\n",
      "Epoch 132/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2857 - val_loss: 0.2917\n",
      "Epoch 133/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2873 - val_loss: 0.3001\n",
      "Epoch 134/2000\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.2854 - val_loss: 0.3091\n",
      "Epoch 135/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2869 - val_loss: 0.2939\n",
      "Epoch 136/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2851 - val_loss: 0.2925\n",
      "Epoch 137/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2861 - val_loss: 0.2973\n",
      "Epoch 138/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2867 - val_loss: 0.3009\n",
      "Epoch 139/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2853 - val_loss: 0.2886\n",
      "Epoch 140/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2856 - val_loss: 0.3167\n",
      "Epoch 141/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2848 - val_loss: 0.2928\n",
      "Epoch 142/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2846 - val_loss: 0.2894\n",
      "Epoch 143/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2842 - val_loss: 0.2924\n",
      "Epoch 144/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2854 - val_loss: 0.2878\n",
      "Epoch 145/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2838 - val_loss: 0.2969\n",
      "Epoch 146/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2827 - val_loss: 0.2947\n",
      "Epoch 147/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2852 - val_loss: 0.2889\n",
      "Epoch 148/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2836 - val_loss: 0.3003\n",
      "Epoch 149/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2855 - val_loss: 0.2984\n",
      "Epoch 150/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2845 - val_loss: 0.3032\n",
      "Epoch 151/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2882 - val_loss: 0.2998\n",
      "Epoch 152/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2838 - val_loss: 0.2856\n",
      "Epoch 153/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2835 - val_loss: 0.2889\n",
      "Epoch 154/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2828 - val_loss: 0.2839\n",
      "Epoch 155/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2843 - val_loss: 0.2883\n",
      "Epoch 156/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2841 - val_loss: 0.2865\n",
      "Epoch 157/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2841 - val_loss: 0.2908\n",
      "Epoch 158/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2828 - val_loss: 0.2865\n",
      "Epoch 159/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2833 - val_loss: 0.2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2825 - val_loss: 0.2871\n",
      "Epoch 161/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2830 - val_loss: 0.2940\n",
      "Epoch 162/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2832 - val_loss: 0.2848\n",
      "Epoch 163/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2857 - val_loss: 0.2986\n",
      "Epoch 164/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2835 - val_loss: 0.3006\n",
      "Epoch 165/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2836 - val_loss: 0.2918\n",
      "Epoch 166/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2843 - val_loss: 0.2895\n",
      "Epoch 167/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2821 - val_loss: 0.2916\n",
      "Epoch 168/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2828 - val_loss: 0.2853\n",
      "Epoch 169/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2826 - val_loss: 0.2884\n",
      "Epoch 170/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2831 - val_loss: 0.2877\n",
      "Epoch 171/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2819 - val_loss: 0.2875\n",
      "Epoch 172/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2813 - val_loss: 0.2933\n",
      "Epoch 173/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2816 - val_loss: 0.2875\n",
      "Epoch 174/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2807 - val_loss: 0.2829\n",
      "Epoch 175/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2829 - val_loss: 0.2852\n",
      "Epoch 176/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2837 - val_loss: 0.2858\n",
      "Epoch 177/2000\n",
      "26/26 [==============================] - 7s 254ms/step - loss: 0.2827 - val_loss: 0.2819\n",
      "Epoch 178/2000\n",
      "26/26 [==============================] - 7s 255ms/step - loss: 0.2821 - val_loss: 0.2867\n",
      "Epoch 179/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2806 - val_loss: 0.2879\n",
      "Epoch 180/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2855 - val_loss: 0.3022\n",
      "Epoch 181/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2841 - val_loss: 0.2982\n",
      "Epoch 182/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2817 - val_loss: 0.2921\n",
      "Epoch 183/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2851 - val_loss: 0.2891\n",
      "Epoch 184/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2803 - val_loss: 0.2878\n",
      "Epoch 185/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2816 - val_loss: 0.2825\n",
      "Epoch 186/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2817 - val_loss: 0.2850\n",
      "Epoch 187/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2805 - val_loss: 0.2861\n",
      "Epoch 188/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2806 - val_loss: 0.2888\n",
      "Epoch 189/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2845 - val_loss: 0.3058\n",
      "Epoch 190/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2815 - val_loss: 0.3008\n",
      "Epoch 191/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2816 - val_loss: 0.2912\n",
      "Epoch 192/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2814 - val_loss: 0.2893\n",
      "Epoch 193/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2809 - val_loss: 0.2881\n",
      "Epoch 194/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2798 - val_loss: 0.2904\n",
      "Epoch 195/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2810 - val_loss: 0.2853\n",
      "Epoch 196/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2798 - val_loss: 0.2875\n",
      "Epoch 197/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2879 - val_loss: 0.2915\n",
      "Epoch 198/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2838 - val_loss: 0.2850\n",
      "Epoch 199/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2795 - val_loss: 0.2834\n",
      "Epoch 200/2000\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 0.2802 - val_loss: 0.2854\n",
      "Epoch 201/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2801 - val_loss: 0.2841\n",
      "Epoch 202/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2796 - val_loss: 0.2857\n",
      "Epoch 203/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2804 - val_loss: 0.2868\n",
      "Epoch 204/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2792 - val_loss: 0.2836\n",
      "Epoch 205/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2790 - val_loss: 0.2807\n",
      "Epoch 206/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2793 - val_loss: 0.2883\n",
      "Epoch 207/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2796 - val_loss: 0.2838\n",
      "Epoch 208/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2779 - val_loss: 0.2819\n",
      "Epoch 209/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2802 - val_loss: 0.2803\n",
      "Epoch 210/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2787 - val_loss: 0.2825\n",
      "Epoch 211/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2798 - val_loss: 0.2814\n",
      "Epoch 212/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2803 - val_loss: 0.2819\n",
      "Epoch 213/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2797 - val_loss: 0.2844\n",
      "Epoch 214/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2776 - val_loss: 0.2797\n",
      "Epoch 215/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2793 - val_loss: 0.2823\n",
      "Epoch 216/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2797 - val_loss: 0.2805\n",
      "Epoch 217/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2782 - val_loss: 0.2831\n",
      "Epoch 218/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2772 - val_loss: 0.2807\n",
      "Epoch 219/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2791 - val_loss: 0.2812\n",
      "Epoch 220/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2779 - val_loss: 0.2875\n",
      "Epoch 221/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2781 - val_loss: 0.2837\n",
      "Epoch 222/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2771 - val_loss: 0.2790\n",
      "Epoch 223/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2771 - val_loss: 0.2798\n",
      "Epoch 224/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2774 - val_loss: 0.2829\n",
      "Epoch 225/2000\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 0.2777 - val_loss: 0.2805\n",
      "Epoch 226/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2767 - val_loss: 0.2823\n",
      "Epoch 227/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2805 - val_loss: 0.2863\n",
      "Epoch 228/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2781 - val_loss: 0.2787\n",
      "Epoch 229/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2786 - val_loss: 0.2850\n",
      "Epoch 230/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2781 - val_loss: 0.2857\n",
      "Epoch 231/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2793 - val_loss: 0.2849\n",
      "Epoch 232/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2795 - val_loss: 0.2853\n",
      "Epoch 233/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2777 - val_loss: 0.2845\n",
      "Epoch 234/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2774 - val_loss: 0.2798\n",
      "Epoch 235/2000\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 236/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2762 - val_loss: 0.2838\n",
      "Epoch 237/2000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2802 - val_loss: 0.2883\n",
      "Epoch 238/2000\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2768 - val_loss: 0.2886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2755 - val_loss: 0.2843\n",
      "Epoch 240/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2764 - val_loss: 0.2815\n",
      "Epoch 241/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2759 - val_loss: 0.2795\n",
      "Epoch 242/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2764 - val_loss: 0.2797\n",
      "Epoch 243/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2764 - val_loss: 0.2807\n",
      "Epoch 244/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2751 - val_loss: 0.2815\n",
      "Epoch 245/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2768 - val_loss: 0.2959\n",
      "Epoch 246/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2757 - val_loss: 0.2783\n",
      "Epoch 247/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2752 - val_loss: 0.2795\n",
      "Epoch 248/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2782 - val_loss: 0.2839\n",
      "Epoch 249/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2769 - val_loss: 0.2795\n",
      "Epoch 250/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2753 - val_loss: 0.2862\n",
      "Epoch 251/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2755 - val_loss: 0.2813\n",
      "Epoch 252/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2766 - val_loss: 0.2799\n",
      "Epoch 253/2000\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.2762 - val_loss: 0.2805\n",
      "Epoch 254/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2769 - val_loss: 0.2869\n",
      "Epoch 255/2000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2752 - val_loss: 0.2802\n",
      "Epoch 256/2000\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.2740 - val_loss: 0.2850\n",
      "Epoch 257/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2755 - val_loss: 0.2907\n",
      "Epoch 258/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2749 - val_loss: 0.2829\n",
      "Epoch 259/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2768 - val_loss: 0.2825\n",
      "Epoch 260/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2756 - val_loss: 0.2806\n",
      "Epoch 261/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2749 - val_loss: 0.2835\n",
      "Epoch 262/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2760 - val_loss: 0.2825\n",
      "Epoch 263/2000\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.2742 - val_loss: 0.2838\n",
      "Epoch 264/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2757 - val_loss: 0.2856\n",
      "Epoch 265/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2742 - val_loss: 0.2786\n",
      "Epoch 266/2000\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.2749 - val_loss: 0.2767\n",
      "Epoch 267/2000\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 0.2751 - val_loss: 0.2772\n",
      "Epoch 268/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2754 - val_loss: 0.2790\n",
      "Epoch 269/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2745 - val_loss: 0.2815\n",
      "Epoch 270/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2747 - val_loss: 0.2782\n",
      "Epoch 271/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2729 - val_loss: 0.2787\n",
      "Epoch 272/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2742 - val_loss: 0.2787\n",
      "Epoch 273/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2744 - val_loss: 0.2792\n",
      "Epoch 274/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2743 - val_loss: 0.2771\n",
      "Epoch 275/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2732 - val_loss: 0.2781\n",
      "Epoch 276/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2733 - val_loss: 0.2800\n",
      "Epoch 277/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2746 - val_loss: 0.2959\n",
      "Epoch 278/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2727 - val_loss: 0.2816\n",
      "Epoch 279/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2753 - val_loss: 0.2841\n",
      "Epoch 280/2000\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.2742 - val_loss: 0.2778\n",
      "Epoch 281/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2730 - val_loss: 0.2785\n",
      "Epoch 282/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2739 - val_loss: 0.2785\n",
      "Epoch 283/2000\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.2733 - val_loss: 0.2786\n",
      "Epoch 284/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2728 - val_loss: 0.2780\n",
      "Epoch 285/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2731 - val_loss: 0.2793\n",
      "Epoch 286/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2709 - val_loss: 0.2808\n",
      "Epoch 287/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2739 - val_loss: 0.2877\n",
      "Epoch 288/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2723 - val_loss: 0.2797\n",
      "Epoch 289/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2732 - val_loss: 0.2839\n",
      "Epoch 290/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2719 - val_loss: 0.2799\n",
      "Epoch 291/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2742 - val_loss: 0.2824\n",
      "Epoch 292/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2731 - val_loss: 0.2890\n",
      "Epoch 293/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2720 - val_loss: 0.2771\n",
      "Epoch 294/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2714 - val_loss: 0.2785\n",
      "Epoch 295/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2735 - val_loss: 0.2837\n",
      "Epoch 296/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2738 - val_loss: 0.2910\n",
      "Epoch 297/2000\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.2754 - val_loss: 0.2776\n",
      "Epoch 298/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2738 - val_loss: 0.2805\n",
      "Epoch 299/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2736 - val_loss: 0.3014\n",
      "Epoch 300/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2725 - val_loss: 0.2774\n",
      "Epoch 301/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2728 - val_loss: 0.2833\n",
      "Epoch 302/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2703 - val_loss: 0.2791\n",
      "Epoch 303/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2705 - val_loss: 0.2786\n",
      "Epoch 304/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2737 - val_loss: 0.2788\n",
      "Epoch 305/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2712 - val_loss: 0.2785\n",
      "Epoch 306/2000\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 0.2718 - val_loss: 0.2813\n",
      "Epoch 307/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2710 - val_loss: 0.2772\n",
      "Epoch 308/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2710 - val_loss: 0.2858\n",
      "Epoch 309/2000\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.2724 - val_loss: 0.2781\n",
      "Epoch 310/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2717 - val_loss: 0.2856\n",
      "Epoch 311/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2704 - val_loss: 0.2899\n",
      "Epoch 312/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2739 - val_loss: 0.2805\n",
      "Epoch 313/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2711 - val_loss: 0.2786\n",
      "Epoch 314/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2704 - val_loss: 0.2811\n",
      "Epoch 315/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2706 - val_loss: 0.2775\n",
      "Epoch 316/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2707 - val_loss: 0.2769\n",
      "Epoch 317/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2694 - val_loss: 0.2852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2689 - val_loss: 0.2792\n",
      "Epoch 319/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2713 - val_loss: 0.2869\n",
      "Epoch 320/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2700 - val_loss: 0.2842\n",
      "Epoch 321/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2719 - val_loss: 0.2781\n",
      "Epoch 322/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2696 - val_loss: 0.2786\n",
      "Epoch 323/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2691 - val_loss: 0.2810\n",
      "Epoch 324/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2684 - val_loss: 0.2777\n",
      "Epoch 325/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2692 - val_loss: 0.2805\n",
      "Epoch 326/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2693 - val_loss: 0.2780\n",
      "Epoch 327/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2713 - val_loss: 0.2780\n",
      "Epoch 328/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2707 - val_loss: 0.2784\n",
      "Epoch 329/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2702 - val_loss: 0.2917\n",
      "Epoch 330/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2705 - val_loss: 0.2787\n",
      "Epoch 331/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2700 - val_loss: 0.2813\n",
      "Epoch 332/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2677 - val_loss: 0.2812\n",
      "Epoch 333/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2693 - val_loss: 0.2770\n",
      "Epoch 334/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2717 - val_loss: 0.2895\n",
      "Epoch 335/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2706 - val_loss: 0.2791\n",
      "Epoch 336/2000\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2688 - val_loss: 0.2783\n",
      "Epoch 337/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2709 - val_loss: 0.3002\n",
      "Epoch 338/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2691 - val_loss: 0.2791\n",
      "Epoch 339/2000\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2681 - val_loss: 0.2780\n",
      "Epoch 340/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2680 - val_loss: 0.2803\n",
      "Epoch 341/2000\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.2764 - val_loss: 0.2828\n",
      "Epoch 342/2000\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2719 - val_loss: 0.2818\n",
      "Epoch 343/2000\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 0.2688 - val_loss: 0.2813\n",
      "Epoch 344/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2685 - val_loss: 0.2809\n",
      "Epoch 345/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2686 - val_loss: 0.2858\n",
      "Epoch 346/2000\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2695 - val_loss: 0.2944\n",
      "Epoch 347/2000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2696 - val_loss: 0.2822\n",
      "Epoch 348/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2678 - val_loss: 0.2775\n",
      "Epoch 349/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2685 - val_loss: 0.2796\n",
      "Epoch 350/2000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.2676 - val_loss: 0.2776\n",
      "Epoch 351/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2682 - val_loss: 0.2774\n",
      "Epoch 352/2000\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.2676 - val_loss: 0.2788\n",
      "Epoch 353/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2674 - val_loss: 0.2800\n",
      "Epoch 354/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2709 - val_loss: 0.2800\n",
      "Epoch 355/2000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.2673 - val_loss: 0.2819\n",
      "Epoch 356/2000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.2675 - val_loss: 0.2790\n",
      "Epoch 357/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2669 - val_loss: 0.2783\n",
      "Epoch 358/2000\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 0.2675 - val_loss: 0.2794\n",
      "Epoch 359/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2679 - val_loss: 0.2804\n",
      "Epoch 360/2000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2662 - val_loss: 0.2786\n",
      "Epoch 361/2000\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.2671 - val_loss: 0.2821\n",
      "Epoch 362/2000\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2688 - val_loss: 0.2880\n",
      "Epoch 363/2000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.2668 - val_loss: 0.2785\n",
      "Epoch 364/2000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2659 - val_loss: 0.2812\n",
      "Epoch 365/2000\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.2678 - val_loss: 0.2799\n",
      "Epoch 366/2000\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.2679 - val_loss: 0.2818\n",
      "Epoch 00366: early stopping\n",
      "CPU times: user 1h 24min 35s, sys: 44min 2s, total: 2h 8min 37s\n",
      "Wall time: 33min 15s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"%%time\\nhistory = model.fit(\\n    X_train_preproc,\\n    y_train.reshape(-1, 1),\\n    epochs=2000,\\n    batch_size=1024,\\n    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\\n    verbose=1,\\n    callbacks=[EarlyStopping(monitor=\\\"val_loss\\\", patience=100, verbose=1)],\\n)\";\n",
       "                var nbb_formatted_code = \"%%time\\nhistory = model.fit(\\n    X_train_preproc,\\n    y_train.reshape(-1, 1),\\n    epochs=2000,\\n    batch_size=1024,\\n    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\\n    verbose=1,\\n    callbacks=[EarlyStopping(monitor=\\\"val_loss\\\", patience=100, verbose=1)],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    X_train_preproc,\n",
    "    y_train.reshape(-1, 1),\n",
    "    epochs=2000,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid_preproc, y_valid.reshape(-1, 1),),\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=100, verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.719810Z",
     "start_time": "2020-05-25T20:59:43.864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3zN9/7A8dcnewgSiRnEqh1C7FJ6taX6M1pVOqyLVoe2qjq1Wl2XtreX6tDholSndau0Rq1WCRIxYiVBzMiSPT+/P745XzkSJJEjkvN+Ph555JzvOp9zxHl/35+ptNYIIYSwXw7lXQAhhBDlSwKBEELYOQkEQghh5yQQCCGEnZNAIIQQdk4CgRBC2DkJBEIIYeckEAhxBUqpaKVU3/IuhxC2JoFACCHsnAQCIUpAKeWqlPpIKXU6/+cjpZRr/j5fpdT/lFKJSql4pdQWpZRD/r4XlFKnlFLJSqlDSql/lO87EeISp/IugBAVzCtAV6A9oIEVwKvANOA5IAbwyz+2K6CVUs2BJ4FOWuvTSqkAwPHGFluIK5OMQIiSeQh4U2t9XmsdC7wBPJK/LxuoAzTUWmdrrbdoYzKvXMAVaKWUctZaR2utj5VL6YUoggQCIUqmLnC8wPPj+dsAZgFHgd+UUpFKqRcBtNZHgWeA6cB5pdRSpVRdhLhJSCAQomROAw0LPG+Qvw2tdbLW+jmtdWNgIDDZ0hagtV6itb41/1wN/OvGFluIK5NAIMTVOSul3Cw/wLfAq0opP6WUL/Aa8A2AUuoepVRTpZQCkjCqhPKUUs2VUrfnNypnAOlAXvm8HSEKk0AgxNWtxvjitvy4ASHAXiAc2A28lX9sM2AdkAL8BXyitd6I0T7wHnABOAvUBF66cW9BiKtTsjCNEELYN8kIhBDCzkkgEEIIOyeBQAgh7JwEAiGEsHMVbooJX19fHRAQUN7FEEKICmXXrl0XtNZ+Re2rcIEgICCAkJCQ8i6GEEJUKEqp41faZ9OqIaVUv/yZFo9ahttftv/fSqnQ/J/DSqlEW5ZHCCFEYTbLCJRSjsBc4A6MGRl3KqVWaq0PWI7RWj9b4PingCBblUcIIUTRbJkRdAaOaq0jtdZZwFJg0FWOH4ExfF8IIcQNZMs2gnrAyQLPY4AuRR2olGoINAI2XGH/BGACQIMGDcq2lELYQHZ2NjExMWRkZJR3UYSdcXNzw9/fH2dn52Kfc7M0Fg8HftRa5xa1U2s9D5gHEBwcLHNiiJteTEwMXl5eBAQEYMxBJ4Ttaa2Ji4sjJiaGRo0aFfs8W1YNnQLqF3jun7+tKMORaiFRiWRkZFCjRg0JAuKGUkpRo0aNEmeitgwEO4FmSqlGSikXjC/7lZcfpJRqAXhjzNYoRKUhQUCUh9L83dmsakhrnaOUehJYi7E+69da6/1KqTeBEK21JSgMB5bqGzQNak5eDov3LkYpRa+GvQioHnAjXlYIIW5aNh1HoLVerbW+RWvdRGv9dv621woEAbTW07XWhcYY2EJmTib9vunH6BWjGbV8FE1mN+F/h/93I15aiBsqLi6O9u3b0759e2rXrk29evXM51lZWVc9NyQkhEmTJl3zNbp3714mZf3jjz+45557yuRaRRk6dCiRkZEA7Nq1i7Zt29K0aVMmTZpEUfefixcvJjAwkLZt29K9e3fCwsLMfYmJiQwdOpQWLVrQsmVL/vrLqMh44IEHzM83ICCA9u3bA0angVGjRtG2bVtatmzJu+++a14rICCAtm3b0r59e4KDg83tU6ZMYcOGIvvN2I7WukL9dOzYUZdG+LlwfevXt2qmo+eFzNPh58J1+8/aa7+ZfjojO6NU1xTiSg4cOFDeRTC9/vrretasWVbbsrOzy6k0hW3cuFEPGDDAJtfet2+fHjx4sPm8U6dO+q+//tJ5eXm6X79+evXq1YXO2bZtm46Pj9daa7169WrduXNnc9/IkSP1F198obXWOjMzUyckJBQ6f/LkyfqNN97QWmu9ePFi/cADD2ittU5NTdUNGzbUUVFRWmutGzZsqGNjYwudHx0dre+4445SvmNDUX9/GDUxRX6v2s2kc+sj13Mg9gALBi9gfMfxtKnZhld6vkJsWizh58PLu3hC2Nzo0aN57LHH6NKlC1OnTmXHjh1069aNoKAgunfvzqFDhwDrO/Tp06czduxYevfuTePGjZk9e7Z5vSpVqpjH9+7d27xTfuihh8w77dWrV9OiRQs6duzIpEmTrnnnHx8fz+DBgwkMDKRr167s3bsXgE2bNpl33EFBQSQnJ3PmzBl69epF+/btadOmDVu2bCl0vcWLFzNokDF86cyZM1y8eJGuXbuilGLkyJEsX7680Dndu3fH29sbgK5duxITEwNAUlISmzdv5p///CcALi4uVK9e3epcrTXff/89I0aMAIz6+tTUVHJyckhPT8fFxYWqVate9TNo2LAhcXFxnD179qrHlaWbpfuozT3R+QkeDnyYGh41zG0d63QEYNfpXQTXDb7SqUJcl2eegdDQsr1m+/bw0UclPy8mJoY///wTR0dHLl68yJYtW3BycmLdunW8/PLL/PTTT4XOiYiIYOPGjSQnJ9O8eXMmTpxYqI/6nj172L9/P3Xr1qVHjx5s27aN4OBgHn30UTZv3kyjRo3ML8eref311wkKCmL58uVs2LCBkSNHEhoayvvvv8/cuXPp0aMHKSkpuLm5MW/ePO666y5eeeUVcnNzSUtLK3S9bdu2ma976tQp/P39zX3+/v6cOnWljoyGr776iv79+wMQFRWFn58fY8aMISwsjI4dO/Kf//wHT09P8/gtW7ZQq1YtmjVrBhjVUitWrKBOnTqkpaXx73//Gx8fH8AIEnfeeSdKKR599FEmTJhgXqdDhw5s27aN++6775qfWVmwm4zAycHJKggABFQPwNvNm11ndpVTqYS4se6//34cHR0B4w73/vvvp02bNjz77LPs37+/yHMGDBiAq6srvr6+1KxZk3PnzhU6pnPnzvj7++Pg4ED79u2Jjo4mIiKCxo0bm/3ZixMItm7dyiOPPALA7bffTlxcHBcvXqRHjx5MnjyZ2bNnk5iYiJOTE506dWL+/PlMnz6d8PBwvLy8Cl3vzJkz+PkVOeHmNW3cuJGvvvqKf/3rXwDk5OSwe/duJk6cyJ49e/D09OS9996zOufbb7+1ep87duzA0dGR06dPExUVxQcffGC2V2zdupXdu3fz66+/MnfuXDZv3myeV7NmTU6fPl2qcpeG3WQERVFK0bFuR0JOy2ymwnZKc+duKwXvXqdNm0afPn1YtmwZ0dHR9O7du8hzXF1dzceOjo7k5OSU6pjr8eKLLzJgwABWr15Njx49WLt2Lb169WLz5s388ssvjB49msmTJzNy5Eir89zd3c0+9fXq1TOrecDIjurVq1fk6+3du5dx48bx66+/UqOGcQPp7++Pv78/XboYEyQMHTrUKhDk5OTw888/s2vXpRvLJUuW0K9fP5ydnalZsyY9evQgJCSExo0bm69ds2ZNhgwZwo4dO+jVqxdgjENxd3e/3o+t2OwmI7iSNn5tOBR3qMjeA0JUZklJSeaX0X//+98yv37z5s2JjIwkOjoagO++++6a5/Ts2ZPFixcDRtuDr68vVatW5dixY7Rt25YXXniBTp06ERERwfHjx6lVqxbjx49n3Lhx7N69u9D1WrZsydGjRwGoU6cOVatWZfv27WitWbhwodl+UNCJEye49957WbRoEbfccou5vXbt2tSvX99sS1m/fj2tWrUy969bt44WLVpYVT81aNDA7AGUmprK9u3badGiBampqSQnJ5vbf/vtN9q0aWOed/jwYavntmbXGQFAI+9GpGWnEZsWS03PmuVdHCFumKlTpzJq1CjeeustBgwYUObXd3d355NPPqFfv354enrSqVOna55jaZwODAzEw8ODBQsWAPDRRx+xceNGHBwcaN26Nf3792fp0qXMmjULZ2dnqlSpwsKFCwtdb8CAAfzxxx/07dsXgE8++YTRo0eTnp5O//79zfr/zz77DIDHHnuMN998k7i4OB5//HEAnJyczDVQ5syZw0MPPURWVhaNGzdm/vz55mstXbq0UPXXE088wZgxY2jdujVaa8aMGUNgYCCRkZEMGTIEMDKJBx98kH79+gFGl9OjR49adSm1NVXR7oSDg4N1WS5Ms+rQKgYuHcj2f26ni3+Rc+IJUWIHDx6kZcuW5V2McpeSkkKVKlXQWvPEE0/QrFkznn322WufWEbS09Pp06cP27ZtM9tGbnbLli1j9+7dzJgxo9TXKOrvTym1S2tdZHSx+6qhRt5GQ1ZUYlQ5l0SIyueLL76gffv2tG7dmqSkJB599NEb+vru7u688cYb1+wddDPJycnhueeeu6GvafdVQ5YpJqISJBAIUdaeffbZG5oBFOWuu+4q19cvqfvvv/+Gv6bdZwRVXKrg5+EnGYEQwm7ZfSAAo3pIAoEQwl5JIAAaVW8kVUNCCLslgQCjneBE0gly84pcIE0IISo1CQQYGUF2XjankitOzwIhhCgrEgi41IU0OjG6fAsiRBnp06cPa9eutdr20UcfMXHixCue07t3b3Pg1N13301iYmKhY6ZPn877779/1ddevnw5Bw4cMJ+/9tprrFu3riTFL1JFWrfg3//+N61bt6ZNmzaMGDHCnObi448/pmnTpiiluHDhgnn8rFmzzNlV27Rpg6OjI/Hx8cCV10Aoy3ULJBBgZAQgXUhF5TFixAiWLl1qta2oka9Xsnr16kJTLBfX5YHgzTffNEf23qz2799Pbm4ujRs3BmDixIl88cUXHDlyhCNHjrBmzZpC5zRq1IhNmzYRHh7OtGnTzNlDT506xezZswkJCWHfvn3k5uaa/xY9evRg3bp1NGzY0Opazz//PKGhoYSGhvLuu+9y2223mbOUPv300/Tr14+IiAjCwsLMgWJPPfVUoUnvSsvuxxEANKzeEIWSnkPCJp5Z8wyhZ8t2Hur2tdvzUb8rz2Y3dOhQXn31VbKysnBxcSE6OprTp0/Ts2dPJk6cyM6dO0lPT2fo0KG88cYbhc4PCAggJCQEX19f3n77bRYsWEDNmjWpX78+HTsa07d/8cUXzJs3j6ysLJo2bcqiRYsIDQ1l5cqVbNq0ibfeeouffvqJGTNmcM899zB06FDWr1/PlClTyMnJoVOnTnz66ae4uroSEBDAqFGjWLVqFdnZ2fzwww+0aNHiiu8vPj6esWPHEhkZiYeHB/PmzSMwMJBNmzbx9NNPA8akkps3byYlJYUHHniAixcvkpOTw6effkrPnj2trneldQsAc90Cy3QUFgVXaCu4bgFgrj/g7OxMWloadevWBSAoKOiK78mi4AymljUQLHNBubi44OLiAlivW1C7du1rXvdqJCMAXBxdqOZWjYT0hPIuihBlwsfHh86dO/Prr78CRjYwbNgwlFK8/fbbhISEsHfvXjZt2mQu/lKUXbt2sXTpUkJDQ1m9ejU7d+409917773s3LnTvEv96quv6N69OwMHDmTWrFmEhobSpEkT8/iMjAxGjx7Nd999R3h4uPmlbOHr62tO83yt6ifLugV79+7lnXfeMWcdtaxbEBoaypYtW3B3d2fJkiXcddddhIaGEhYWZi4jWdC2bdvMAHe96xbUq1ePKVOm0KBBA+rUqUO1atW48847r3q+RVpaGmvWrDHXISi4BkJQUBDjxo0jNTXVPN6ybsH1kowgn7uTO+k56eVdDFEJXe3O3ZYs1UODBg1i6dKlfPXVVwB8//33zJs3j5ycHM6cOcOBAwcIDAws8hpbtmxhyJAheHh4ADBw4EBz3759+3j11VdJTEwkJSXlmiN4Dx06RKNGjcwZPUeNGsXcuXN55plnACOwAHTs2JGff/75qtfaunWruYhOUesWPPTQQ9x77734+/vTqVMnxo4dS3Z2NoMHDy4yEJTFugVbt24FICEhgRUrVhAVFUX16tW5//77+eabb3j44Yevea1Vq1bRo0cPs1rIsgbCnDlz6NKlC08//TTvvfeeOQ9RWa1bIBlBPndnCQSichk0aBDr169n9+7dpKWl0bFjR6Kionj//fdZv349e/fuZcCAAWZDZkmNHj2ajz/+mPDwcF5//fVSX8fCsqbB9axn8OKLL/Lll1+Snp5Ojx49iIiIMNctqFevHqNHjy5yltLrXbdgxYoV5roF69ato1GjRvj5+eHs7My9997Ln3/+WazyX96OU9QaCAWn2y6rdQskEORzd3InPVsCgag8qlSpQp8+fRg7dqz55XLx4kU8PT2pVq0a586dM6uOrqRXr14sX76c9PR0kpOTWbVqlbkvOTmZOnXqkJ2dba4hAODl5WXOtV9Q8+bNiY6ONtcHWLRoEbfddlup3tvNvG5BgwYN2L59O2lpaWitWb9+fbFmok1KSmLTpk1Wr3WtNRDKat0CCQT53JzcJCMQlc6IESMICwszA0G7du0ICgqiRYsWPPjgg/To0eOq53fo0IEHHniAdu3a0b9/f6s1BWbMmEGXLl3o0aOHVcPu8OHDmTVrFkFBQRw7dszc7ubmxvz587n//vtp27YtDg4OPPbYY6V6X9OnT2fXrl0EBgby4osvWq1b0KZNGwIDA3F2dqZ///788ccf5vv+7rvvzMbkgizrFlh88sknjBs3jqZNm9KkSROrdQssaxcUXLegffv25voBXbp0YejQoXTo0IG2bduSl5dn9iiaPXs2/v7+xMTEEBgYyLhx48zXXLZsGXfeeafVKnJwaQ2EwMBAQkNDefnll4GyXbfA7tcjsOg5vyfODs5sGFU2/XKFfZP1CCqWyrZugaxHUErSWCyE/bL3dQuk11A+d2d3zqeeL+9iiEpEa41SqryLIYqpsqxbUJpaHskI8klGIMqSm5sbcXFxpfpPKURpaa2Ji4vDzc2tROdJRpDP3Vl6DYmyY2kQjI2NLe+iCDvj5uZmNSCuOCQQ5JOMQJQlZ2dnGjVqVN7FEKJYpGoon4wjEELYKwkE+Swji6VOVwhhbyQQ5HN3cidP55Gdl13eRRFCiBtKAkE+d2djvg6pHhJC2BsJBPncnYxAkJFzfRNnCSFERSOBIJ+ZEUjPISGEnZFAkM+SEUjVkBDC3kggyCcZgRDCXkkgyOfmZAzJloxACGFvbBoIlFL9lFKHlFJHlVIvXuGYYUqpA0qp/UqpJbYsz9WYVUOSEQgh7IzNpphQSjkCc4E7gBhgp1Jqpdb6QIFjmgEvAT201glKqZq2Ks+1SPdRIYS9smVG0Bk4qrWO1FpnAUuBy9d7Gw/M1VonAGity20eaMkIhBD2ypaBoB5wssDzmPxtBd0C3KKU2qaU2q6U6lfUhZRSE5RSIUqpEFvN5ujh7AFAWnaaTa4vhBA3q/JuLHYCmgG9gRHAF0qp6pcfpLWep7UO1loH+/n52aQgPu4+AMSlxdnk+kIIcbOyZSA4BdQv8Nw/f1tBMcBKrXW21joKOIwRGG64qq5VcXV05VzqufJ4eSGEKDe2DAQ7gWZKqUZKKRdgOLDysmOWY2QDKKV8MaqKIm1YpitSSlHTs6YsVymEsDs2CwRa6xzgSWAtcBD4Xmu9Xyn1plJqYP5ha4E4pdQBYCPwvNa63OpmalWpJRmBEMLu2HSFMq31amD1ZdteK/BYA5Pzf8pdLc9anE4+Xd7FEEKIG6q8G4tvKrU8JSMQQtgfCQQF1KpSi/Op58nTeeVdFCGEuGEkEBRQy7MWOXk5JKQnlHdRhBDihpFAUECtKrUApHpICGFXJBAUYBlUJhmBEMKeSCAoQOYbEkLYIwkEBcgMpEIIeySBoADJCIQQ9kgCQQGWGUglIxBC2BMJBAVYqoZkKmohhD2RQFCAVA0JIeyRBIICpLFYCGGPJBAU4OzgjINykIxACGFXJBAUoJTC3cldMgIhhF2RQHAZd2d3yQiEEHZFAsFl3J0kEAgh7IsEgst4OHtI91EhhF2RQHAZd2dpIxBC2BcJBJeRqiEhhL2xm0CgNWRnG7+vRjICIYS9sZtAMGsWuLhA+jW+4yUjEELYG7sJBA757zQ39+rHSUYghLA3dhMIHB2N39cMBE7u0mtICGFXJBBcxhII9LUaE4QQopKQQHAZD2cPYtNi8ZvlZ/tCCSHETUACwWXcnNwAiEuPs3GJhBDi5mB3gSAv7+rHHYo7ZPvCCCHETcRuAkFxew21qdnG9oURQoibiN0EguJWDU3rNY1R7UbhoOzmoxFC2Dm7+bYrbiBwdnSmsXdj8nQeuXnXOFgIISoBCQRFcHV0BSAzN9OGJRJCiJuD3QWCazUWA7g65QeCHAkEQojKz+4CgWQEQghhzW4CQXF7DYFkBEII+2I3gUAyAiGEKJoEgiJIRiCEsCcSCIogGYEQwp7YNBAopfoppQ4ppY4qpV4sYv9opVSsUio0/2ecrcpSkl5DLo4ugGQEQgj74GSrCyulHIG5wB1ADLBTKbVSa33gskO/01o/aatyWJSmaigrN8uGJRJCiJuDLTOCzsBRrXWk1joLWAoMsuHrXVWJeg1J1ZAQwo7YMhDUA04WeB6Tv+1y9yml9iqlflRK1bdVYaSxWAghilbejcWrgACtdSDwO7CgqIOUUhOUUiFKqZDY2NhSvVBpG4s3Rm0kIyejVK8phBAVgS0DwSmg4B2+f/42k9Y6Tmttue3+EuhY1IW01vO01sFa62A/v9KtHFaajGDX6V3cvvB2nlv7XKleUwghKoJiBQKllKdSxrzMSqlblFIDlVLO1zhtJ9BMKdVIKeUCDAdWXnbdOgWeDgQOFr/oJVOiuYbyM4KoxCgADscftlWxhBCi3BU3I9gMuCml6gG/AY8A/73aCVrrHOBJYC3GF/z3Wuv9Sqk3lVID8w+bpJTar5QKAyYBo0v+FoqnNBlBYkYiYCxoL4QQlVVxu48qrXWaUuqfwCda65lKqdBrnaS1Xg2svmzbawUevwS8VJICl1Zpeg0lZSYB4O4sgUAIUXkVNyNQSqluwEPAL/nbHG1TJNuQjEAIIYpW3EDwDMad+7L86p3GwEbbFavslSQQWEYWWwKBm5ObrYolhBDlrlhVQ1rrTcAmgPxG4wta60m2LFhZK0kgcFAOODk4SUYghLALxe01tEQpVVUp5QnsAw4opZ63bdHKVkl6DYHRTmCZYsJSVSSEEJVRcauGWmmtLwKDgV+BRhg9hyqMkmQEYP3ln6eLGT2EEKICKm4gcM4fNzAYWKm1zga07YpV9kocCBwvBYLs3GwblEgIIW4OxQ0EnwPRgCewWSnVELhoq0LZQkm6j4J1RpCdl82pi6fYc2aPDUomhBDlq7iNxbOB2QU2HVdK9bFNkWzjejOCBh81IE/noV+vUImQEEJcU3Ebi6sppT60TPymlPoAIzuoMK6njSAnL0faCYQQlVZxq4a+BpKBYfk/F4H5tiqULZS011DBLqPZedJGIISovIobCJporV/PX2QmUmv9BtDYlgUrayXNCHo17GU+lkAghKjMihsI0pVSt1qeKKV6AOm2KZJtlDQQPBz4sPlYeg0JISqz4gaCx4C5SqlopVQ08DHwqM1KZQMl7TUUWCuQ57oZ6xBIRiCEqMyKFQi01mFa63ZAIBCotQ4CbrdpycpYSTMCgPfvfJ/gusFWGYE0GgshKpsSrVCmtb6YP8IYYLINymMzJW0stnBycCInL8d8LtVEQojK5nqWqlRlVooboDQZAYCzg7NV1ZBUEwkhKpvrCQQVamRVSdsILJwdna2yAMkIhBCVzVUDgVIqWSl1sYifZKDuDSpjmXF0LJuMYH3ketKzK1SnKSGEuKKrBgKttZfWumoRP15a6+Iuc3nTcHC4/ozgZNJJ+i7qyw8Hfijj0gkhRPm4nqqhCqc0GcHljcUX0i4AkJCeUJZFE0KIcmN3gaCkvYYurxqyLGifmp1alkUTQohyY3eBoDRVQ5aVygAuZhq9Z9Oy08qyaEIIUW4kEFyDs4MzqVmX7v6TMoyMQAKBEKKykEBwDc4OzqRkpZjPLRlBweAghBAVmV0FgtL2GirYHmBWDeVIRiCEqBzsKhCUttdQQWZjsWQEQohKwu4CQWl6DRUkjcVCiMrG7gJBaaqGCpLuo0KIykYCwTVIRiCEqOwkEFzD5RmBBAIhRGVjV4GgNL2GCjUWZ0hjsRCicrGrQCBVQ0IIUZjdBYIS9xq6rGrI0kgsjcVCiMrC7gLB9WYEFhk5GbJ+sRCiUpBAcA2XZwQFSfWQEKIykEBwDVfKCEACgRCicpBAcA2X9xoqSAKBEKIysKtAUNpJ565EupAKISoDmwYCpVQ/pdQhpdRRpdSLVznuPqWUVkoF27I8ZTHXEICXixcgGYEQonKwWSBQSjkCc4H+QCtghFKqVRHHeQFPA3/bqiwWpakasvQMCqodhKNyBMDXwxeQLqRCiMrBlhlBZ+Co1jpSa50FLAUGFXHcDOBfQIYNywKULhA4Ohhf/hODJ5rVRJZA8M6Wdxi0tKi3JIQQFYctA0E94GSB5zH520xKqQ5Afa31L1e7kFJqglIqRCkVEhsbW+oClSYQDG4xmD/H/sm4DuPMjKBWlVoA/BH9B9tObCt1eYQQ4mZQbo3FSikH4EPguWsdq7Wep7UO1loH+/n5lfo1SxMIHJQD3ep3QyllVgU19W4KQHZetrQTCCEqPFsGglNA/QLP/fO3WXgBbYA/lFLRQFdgpS0bjB0cSt5YXJQmPk3Mx+k56TLCWAhRodkyEOwEmimlGimlXIDhwErLTq11ktbaV2sdoLUOALYDA7XWIbYqUGkygqI08W5i9Twjx+bNG0IIYTM2CwRa6xzgSWAtcBD4Xmu9Xyn1plJqoK1e92rKLBD4WAcCqR4SQlRkVx42Wwa01quB1Zdte+0Kx/a2ZVmg7AJBPa96uDq6kpmbCRgDyyw9iYQQoqKxq5HFZRUIPF088XD2MJ9LRiCEqMgkEJSSp4un+VgCgRCiIrOrQFBWvYYAyQiEEJWGTdsIbjYeHpB6HbNCbBy1EVdHVwA8nSUjEEJUDnYVCHx8ICEBtAalSn5+74De5uOCGYHMOSSEqMjsqmrIxweys68vK7CQqiEhRGVhV4HA29v4HR9//TyvNrcAACAASURBVNeSxmIhRGVhV4HAx8f4XRaBQDICIURlIYGglKSxWAhRWUggKCWrxmJZslIIUYFJICglqRoSQlQWEghKyVI15KAcJBAIISo0uwoE7u7g5lY2gaCJTxN83H2oXaU2aTlGIDieeJxZ22ahtb7+FxBCiBvErgIBGF1IyyIQPND6AU5PPo2Pu4+ZEXy771umrpvK+dTz1/8CQghxg9hdIPDxgbi467+OUgpXJ1c8nT1JyUoBID7diDBx6WXwAkIIcYPYXSBo0ACiosruetXcqpGUkQRcCgSW30IIURHYXSBo3RoiIspuOurqbtVJzEgECmQEaZIRCCEqDrsLBK1aQWYmREaWzfW83bzNQJCQkQBI1ZAQomKxu0DQurXxe//+srledbfqJGQkoLWWqiEhRIVkd4GgVSvjd1hY2Vyvult1snKzyMjJkKohIUSFZHeBoEoVuPVW+OoryMq6/ut5uxlTmnq840HMxRigZFVDw34YxuK9i6+/IEIIUUp2FwgAXn4ZTp6EDz64/mtVd6teaFtJqoZWHlrJpuObADibcpbQs6HXXyghhCgBuwwE/frB/ffDq6/Ctm3Xd62iAsFPB3/i4x0fX/PcrNwsMnMzuZh5EYBWc1sR9HnQ9RVICCFKyC4DgVJG1VCDBjB6tLF8ZWl5u3sXuf2pX58i7GwY6g3FoQuHijwmOTPZ+J1l/Lb0OhJCiBvJLgMBgJcXLFwIx49D8+bwzjulu05RGQFALc9aLA436v5/OvhTkcdYMgHLb4uMnIzSFUYIIUrBbgMBQM+esGIF1KgBr7wCjo6wZk3JrmFpLAZoUK0BB584SP+m/QFwdnAGIDs3u8hzLZmAJTOwsIxUFkKIG8GuAwFA//6wcye0awd5eTBlSslGHVdzq2Y+Pv7McVr4tqBdrXbEp8fj5OAEGG0BAFpr1hxdY85NZAkAl2cElgFqQghxI9h9IACjS2loKCxdagw0GzgQ1q0r3rkuji4ANKreyNzm4+5Ddl42p5NPA5d6EX2771v6L+7Pk6ufBC4FAEtmYJGUKRmBEOLGkUBQwLBhMGYMrF4Nd9xhVBsVx64Ju9gxfof53MfdWAHnSPwRAM6knCHmYgzPrHkGF0cXFoQt4HDcYTMAXJ4RlHXVUJ7O44XfXyAyoYzm1RBCVCoSCAqw9CY6ehTatoUXXoDirDHToU4HfD18zeeWQHA47jBgjA94YvUTpOek8/k9nwNwJO6IWTWUlZtlVh/B9WUEP+z/gQOxB6y2nUw6ycw/Z7Ls4LJSX1cIUXlJILiMUtCkCTz5JBw6VLqpKCyB4EzKGfP3luNbeLDNg/Rs0BOAC2kXrDKBgo+vlRGcTTnLrtO7Cm3XWjPsx2G0/bSt1XbLSGfpniqEKIoEgiu47z5wcoJnnoHY2JKdawkEFieSTpCQkUC72u3MzOFC2gWrtoHY1EsvcrXG4jydR50P6hD8RXChJTEtK6Pl6Tyr7Za5j2QyPCFEUSQQXEGNGkY10fbt0KEDnDpV/HMLBgJH5Wg+blerHVVdq+Lk4FQoI7BkD3D1qqGC1TvnUs9Z7TuedLzIcywZwbUCQb9v+jHn7zlXPeZmEZUQxapDq8q7GEJUChIIrmLkSNi6Fc6fh+nTi39ewUDweKfHzceBtQJRSuHr4WtkBAXGD1h6GAHM2DyDb/Z+U+S1t8dsNx8fjD0IGHf8i8IWEZ0YDVwav2BRnIwgT+exLnIdW09uvdbbuyn85+//MOzHYYWyIiFEyUkguIbgYJg4Eb7+GpYvN8YaXIu7s7v5uHmN5kzpNoXbG92Ol6sXAL4evsSmxVrNUnom+YzVNR5Z9ggDlgwwq3ssDl44aAaaiAsRbD2xlQFLBjBy+Ui2HN8CQFXXqlbnFCcjuJB2gVydW6gcN6v49HgycjJIzU4t76IIUeE5lXcBKoK33oKNG2HIEKM30XffQa1axkC0u+4q+pyvBn5FxIUI7mt1H7Wr1Lba5+vhy4pD1n1T39ryVqFrrD6ymj+i/2BY62G8tO4lejbsScSFCP7R6B+sOLSCx1c/bnX836f+BiBXW4+IK05GYAkAZ1POXvGYm4mlHeVC2gWquFQp59IIUbFJRlAMVarApk0wbx6cPQt33gkDBhizmK5cWfQ5Y4PGMvOOmYWCAGDV1dTi8rEEFgdjD5KVm8V7295jwJIBRCVG0dK3Je1rty907M7TOwGj11HBBuOCGcH2mO3M+XsOa46u4Wj8UfMYSxvFlQKB1ppzKefMx+9ueZfjiUW3SZTWxcyLfLfvOwDWHF1jVn19HvI5veb3sjrWEghkESAhrp8EgmKqXh3Gj4c5cyAmxmhErlULxo0zsoWFCyGuwHdSdrYxDiEqqvC13JzcAAiqHcT6ketZNeJSo2fI+BDe6P2G+TwiLsJqIFiezqOFbwsWDl7IxlEbeaD1A4Wur9FWgcUSCJIyk7jrm7uYtGYS/Rf3585FdwKwImIFw34YBhijnFOzCle3vLjuRWp/UJsLaReITozm5Q0vsyBsQZGfVW5eLhk5GWTkZHDLnFtYum9pkcdZzN8zn6/3fM2isEUM/2k4x+KP8eBPDzJ903QAfo74mS0ntliVqyKsD3047jC7z+wu72IIcU02rRpSSvUD/gM4Al9qrd+7bP9jwBNALpACTNBaHyh0oZvIsGHG5HQtWxrdSwcOhNtvN/Y1bWqMTO7Z0+hyOnMmJCfDhx+Cm/HdT24uhB03osOMPjO4vdHtVtev6lqVZj7NzOcRFyI4EnfE6pieDXviX9Wf5r7N+e3Yb1b7annW4lzqORLSE8yZUQveNRcMEFGJUWitGfzdYKtrnEs9R2OXxuZzrTUz/5wJGF9ultlRj8YfJSMng4uZF6npWdM8fuTykSwJX0LI+BCOxB9hxE8jGN5meJGfZ0ZOBmNXjgWgftX6AOw5u4eEjAQOxx1Ga03I6RAATl48SQvfFkDxMoLDcYdp5tMMpdQVj7GlwE8DyczNJHtatjnvlBA3I5tlBEopR2Au0B9oBYxQSrW67LAlWuu2Wuv2wEzgQ1uVp6woBUOHQuvWxvTVO3YYjckTJkB0tDGLae/e8ED+jfqnn4K7O/zf/8HFi/D44xD+40AAItZ35sABOHcOlDb+KTycPWnkfWneokMXDpkjlF/t+Sr7Ju7Dv6q/uX9qj6k80ekJ83kX/y6A9Z1yXHqcVTdWwPxiOhR3qNCX1OXVQwV7Kh2LP2ZmKEfijzD196kEfhpITl6OecyS8CUAbDmxxdxWVCP0qkOr6Divo/n85MWTAGyM2ggYX+SRCZFm28aJpBOA0S5gBoIrZATrI9fT/OPmfLLzkyL3F6WkPZCSM5N56OeHzN5al8vMzQTg92O/l+i6onR2nNrBhbQL5V2MCsmWVUOdgaNa60itdRawFBhU8ACtdcGKcU+gwvUFrFYNPvkEPv8c4uONnz59jDv/gcb3Pf/3f/C//xnHzpsHt7tNwe3fSUx53I+uXaFbN9ALf4NjfRk2oCY1HW/B09mTQc0HkZ6TzpJ9S/B282bG7TNo5dfa6vWru1Xn47svrYbWpZ4RCDp90Yldp3eRnJlMzMUYWvldisGLhiziwONG4rUpepPV3TxYd2UF6/UUIhMiiUowMprDcYf54cAPnEs9Z961F2yQLtggblmOs6AxK8aY02FUc700i+vGaCMQpGWnWV3jRNIJlkcsx2+WnzmDa1H/8f+54p/0XdQXMLriXmkacAutNeNXjqfVJ61KFAy2nNjCkvAlDPx2YJH7LY3Y3x/4vtjXFKWjtabPgj588GcZrD9bCmdTzjJ46WAS0ivm6H1bBoJ6wMkCz2Pyt1lRSj2hlDqGkRFMKupCSqkJSqkQpVRIbEmH+d5AXl7g7W3MXJqXZ0xal5RkNCgvXGhkA7/9But+dyDhbFW2bwcfH6MdYWK/f/BFr98J2eHEPf/wofOWM5z9zKiD331mN8Q348EHjbaKRx+Fhx8uemU1SyAA6PJlF3xn+ZKVm8WrvV41t7f2a01Tn6bUqVKHjdEbzS6q9byMfx7LXe7FtHRSMtJZFrGM/k3741/Vn8jESKISjUAQnx5vZg8/7P+Bhh81pPnHzc3X+SP6D5rXaI6TgxNhZ425Ot7b+h4rIlaw49QOq0V9Ota9lBkcvHDQfLw4fDGujq44KAeOJx7n+d+ft3q/lqqh7Nxs9p7bS05eDl+Hfg2AQnEu9RwRFyKu+u+26vAqvtzzJREXIsz3VhyWgBl+PrxQFVV6droZrIqaDkSUrcSMRNKy06wGZt5IW09sZcWhFWaHjYqm3BuLtdZztdZNgBeAV69wzDytdbDWOtjPz+/GFvA6Vc3v0v/IIzB3rjGrqVJGm0GXLnDwoJEtvP++0fC8Zg2kpcHpKC88HavhfcFY5CZrw4v8+qtRvTRvHixebFRPPfIIPPYYVM007vj3bb7FfO1cnWtOZndvy3v5adDvDLxlMLvWtGbRIsVtAbfxw4EfyMnLYXa/2Zx49gQ/DfuJ3LxcZm6bif+bnak6oyaRCZF0ch+Bv0djIhMiiUyItKpqal6jOR9u/5ATSSe4mHmR+1reZ+4LqhNES9+WvLftPe7/4X5eWv8Sg78bTJcvu3As4Ri9Gvbij1F/mO0DFpbpvXef2U372u2p51WPFYdWWPV0gktVQ/ND59Pus3a8vP5lAO5ofAe/PPgLwBWrbiwsQQowM5viKHjdX4/+arXPEiTqVKnDwQsHyczJLPZ1y5vWmjErxrA+cr3NX+tE0gkGLx183TPuWm5myqvzgGWKmMvH/Vhk5mRaTSx5s7FlIDgFFPzf7Z+/7UqWAoOvsr9Scnc3uqJ6eBjP+/Qx2hoiImD9ejg68xvCJ4Zz8e8hxMcb7QnffAN//WWMafjzT2Ogm+d3W3D+PIJnxvjjsfV9WLQG9ozhlpg36XT+EzoGOXFfUF9WPriM8WNdGDUKGuT1MruZrlgQwKKFDtzb8l7ubnY3n4Z8SrLrAXSqL+waz5v3Pcz2X5uw9cRW/j71N2Paj6GX2xMwdx/3+7wLGCOa33DK5Ms7fzTf34g2I2hd06jO+vHAj1xuQocJ3BZwm1W7B8DtjW43G82D6wbToFoDws+HFzo/Lj2OC2kX+PPknwDM+nMWAG/2eZPgusEAV7zLz8rNotMXnZi7cy413Gvg4uhS5N37orBF5mC9gqITo2lQrQG1PGvxy5FfrPadSjb+1Ac0G0BOXo5VlnOzS8hI4L+h/y001sUW1keuL5M7aTMQlFN34tg0IxAUnDOsoIYfNaTD5x1uZJFKxJaBYCfQTCnVSCnlAgwHrHrdK6WaFXg6ALDuHiPwcfehTc02ODgYmUTNmvDQQ9C1K6xdC8eOGWMbTh/zIWx9c+bOVeyZ+xxp4Xcxs8fXHF80jWNLJ1K7NsyYAT16XLr2zPEDzMc71vszejRMmgSJ/3uRKnG94NtVRD0TyaoJ83B0VPxfjSl4hk/CdfO/6JX+ITumfwyxrflg3BCaRb2PWryWl14yGs89T92NY3otBjT9P+pWqWu+jqNyJHtaNi19WwKYvYDqVTHuGaq7GtVFc/rPMTOLZj7NmNxtMmAEFsvI6jpV6hByOgS/WX6FurI2r9EcXw9fPJw9rO7ckzOTWbpvKVprtsdsJ+R0COdSz9HctzmBtQL5LfI37v/hfjOwpGSlMH7V+EJVUmAEgsbejenfrD+/HvnVarLAUxeNQHB3s7sBI9PIzs0m5mIMuXm5jF0xtsjgcjOwfF6XtxUVZduJbdf15WvpIHCtrO1Kzqac5dvwb80vYltnBKOXjy5yOverZQQ5eTmcSz3H/tj9Ni3b9bBZnzatdY5S6klgLUb30a+11vuVUm8CIVrrlcCTSqm+QDaQAIyyVXnsQcuWxo/F88/D008bAcQ5f/qhV14xxjjMmQPp6Q043mIyX+7/kKhdjXnuSWN7zZrdCai5iXFPQECA8ZOQAF5erThx4j907gwjh4ODAyxaZKzsFrXzORrkQv0+xnPUSnDIpd8uRVD3V5lQK4gTm3qTk5tH7DknVg5fxZwdc1Dn2/GPR2BDjD88CL475/LLtH409fHh1V6v4uTgxJigMVR1rcqZ587g5eJFx3kdiU+P55Wer/Dkr0+a73dS50nM3jEbAG93b7QGf89GLAhbwF1N7qKlX0vm/D2H9/96Hx93H/46+Zd5bqPqjegT0Idxq8YRejaUhPQEpvWaxqnkU2TmZvL3qb85k3yGOl51zHOiE6O5o8kdTOo8iQWhC5i8djLz/m8eTg5OZkZwW8BtNPNpxpTfpjB+1XgAvvy/L5kfOp9tJ7dx6MlDhf4d07LTOJN8hiY+TcrmD+MKkjOTWXloJR3rdjQDMmAOFLxWIDifep5b599Kn4A+bBi1oVRlOJlkBAJLB4TiWHVoFVVdq3JbwG3cuehOws+H81YfY2T+tYJSdm42Lee2ZEr3KTwW/FiJypqalcqCsAVk52UzpOUQAN7d8i6eLp5mICoqEBRcHyQrN8us9rwWrTXpOel4OHuUqJylYdPOzVrr1cDqy7a9VuDx07Z8fQEul/3NKWVse+45y5YP+M+gGXg4ezB/vnE337q1MZq6IC9jmiQaNDDWaQgNhfr1oXFjo+HaIjfXaMM4c8aRxYsdWbcO1q/3RuuH8fQ0GtFbroPs7CZkZ3/EJ9roTeWS0w2fxEGc++t27rzVh7//hlatPOmUMoNRw42pPDw8atO8ObRLe45DTGBoq/tJzkpmY/RGfjv2G638WvFct+fMutg5c+Dw3urQYD/9Fvezej8TVk2wmhOqrpc/Y4PGkpqdyrtb32V91HrWRxl15M4OzmTnZbPi0ArGdxhPZm4m3+37jlPJp2jq3ZSgOkE83/15Zv45k6quVXmv73v8N/S/NKzWEG83b9Y8vIY7Ft1hzio7btU4AGLiY8nTeTgoB5Izk/li9xcMbD6QGZtnsDBsIeennMfP89ptYv9c8U8Cqgcw7bZpVtv3nNlDE58mheaeAuNLZvhPw1l9ZDXta7dn94Td5niLojKCUxdP4ebkRg2PGhyIPcAvh38xM7PNxzdfs4xXEpMcY7xmUnSR+/N0Ht2/6s6jHR9lTNAY8nQeA5cavbT069qsLtx+yujinJCRYH6ml7/fnLwclkcs51jCMZ5c/WShQJCYkcj7f77P1B5Ti/zMLFWMx+KPmdvm7Z6Hh7OHOYPA+bTCgWDnqUvVXpEJkVZB92r+te1fvLT+JRJeSLDqWGELMspFmHccShkN2NdSrRrcdlvR+xwdjWAC8NJLxjWVMto9ateG06fh1VeNUdkeHsa+F1+EKlV8cHVdTsxzxkR/HToYASvF6HjD8uUFX2U8Dk5jafOxI4MGvUg73+cJC/mRqi3vxfuIM5GR0GySsdIcDxX+D93V5262x6/Gy8WLwFqB7D23l9lz07kDRfO8SbwU5MfTWx7EQTnwfPfn6VS3E6/98RoTf5nIjE0zyMnL5WJWEp1q9mT+ExOp9ij463/RmuP85+//sC5yHftj9/Nhx9X89pvirrsas2/iPsLPh9Ply/wPOGIQaS1WMHr5WA7E7iMhI4HIhEiW7ltq9nJaELaAKd2nmOU+HHeYlKwUOtS5VNccnx5v9pJ6NPhRsytwVEIUHeZ14NYGt5KcmUxUYhRNvJsQUD2AYa2HMeKnEQB4u3kTejaU7THb6Va/G2AdCLJzs4lLj8P/3/74uPsQNzWOmdtmsiBsgVWX5JSsFLO77IaoDYxdMZYl9y2he/3uV/tTMjOCnad2cjT+KE19mlrt33tuL3+f+hsfdx/6Nu5r3nmD9bodluwuT+eRmJFYaE2QBWELeP735812p8u7TI9cNpLzqedZe2wt+87vY/lwqz844FIAOJZg/M7MyeRE0gkclAO5ecb8XkW1EWw7uc18fDjucLEDwUvrXwIg9GwovQN6F+uc0pJAIGzG/dINN83ze5VWqwY//VT08QD+/rBlizEuIzsbWrQwzt2zx2go9/U1Rm7/+KMjR44YXXNjYx2pXv0BHiww20b16kbX3HrR8wjfuQc1aDz6ZBf4bhnbtaJ24zhqeXtRvXYiqs4QMjc/zZ35baNO7oNpNupFmsQ+y74dNRkyDe5vEs0bsVM4nXLpLtkn5H127vPhqafyN9zyEDz4Hftj9/Pj0GU8N6A/Z87Ar79CYKA7net1Zu3Da/n6x9N8t3wwPNaeRXsX4OroSlXXqowLGseXe740rz9z20x6B/Rm7dG1dPXvao6NWDRkES6OLswPnc/tAZdGpn+681N6NuzJ0n1LzV5dW09sxUE5MLzNcM6lnGPtsbUsi7hUx/3XP/+i61ddeXnDy2wYuQGllLmuRXZeNk/9+hSf7zKWV41Pj+d44nHWHlsLGFUerfxacSD2AI8sewR3J3f+PPknJ5JOoNEsCb8UCLJzs3F2tJ4eHS61ERyJP0KzOc3IfS3X6m7e0nPp16O/0uCjBvRreimzWxFxqTG7YNtAnQ/qEPFEhNXAzLXH1nIh7YI57uRMyhliU2Px8/Tj1MVTLNq76NJ1D63gRNIJGlRrYFVWy0BKy1oiZ5LPkKfzyNN5HIozqvjOp54nT+cx9fepNKjWgOFthvPzwZ8Z0GwAvxz5pdAsAWAEr/3n99OmZhszKysY5CyB4Pdjv9M7oHeRn+P1UhVtPvfg4GAdElL8Ln6i8ktKMtpAXn/daDyfONGosmrSxOiK++23sGzDCYLbVmXEkOqsXg1//AFnzkBWltHwPn68EYBSU+Hdd41uv15eRttIbCzglgB3vEDd45PJ7fc451MuoD8Jo0cPRVyc0csLx0wY1w1CHqPO6QmcOWNkPJb/Yh07GmX6/nsjIFate5ZTXiuYNng4depC/BkvFrv2YP/F7bzU4QO+jpjF+bRz6GuMs/R28yaoThC7Tu/C08WzUN1+N/9ubB3zJydPwnt7n+Cz3Z9wd7O7GVvvAzzTWxBT80vGrxrPpM6TqOZWjQ/++oA8nWdOJVJQ9/rdzYZ0MALJO1veYdXhS/NlDW4xmOjEaHLzctk7cS8nkk7Q5csuPNrxUab3nm4O2kvOSqbae9VwcXQxq/N2T9hNUJ0gwGgruX3B7easupdr6tOU+PR4FKpQI/G4oHF8MfALjsQdoc+CPmabDcBTnZ9izo45jAsaR1RiFKPbj+aRZY8ARueFiAsRfHDnB2w6vok+AX1IzEjkma7PMG3DND7e+TFX4+nsySs9X+HlDS9bbf/9kd8ZuWwkXf278lG/j8wgsy5yHV/t+Yql+5byxf99wfA2w/l4x8fsObuH7/dfGogYXDeYXad38c4/3uHFW1+8ahmuRCm1S2sdXOQ+CQRCWEtNvVRtlZRkZDDx8cZEg2++CfWbJBMZncPrL3jz7LNGVdbJk/Daa8Y5bdsajehduhhTjxw9amQzX31lVJFlZxtjRlq0gClTLnvxmvtQvd9AL/svrjVjyBw8BA4NhAst4MStqEeDIdcFfTaQZk59SPHejsf+x+nYPYnv84zqnn51HiEhQfH3wntg2DCaxryB587XCAuDprfuIbJvMEvu/Y7Xhg7lxAk4elQz9e+HzalBhrYayqDmg8wvR4uZfWfywroXaOnXkm7+3Th44SDbxhrVHt+Gf8tPB39i0ZBFuDu7886Wd3hlwyuETwznnyv/yY5TOwBoX7s9cWlxuDq50qVeFxaHL2bpfUvxcvViwBKjF1u/pv1wUA6cuniKvef2mu0vtavU5mzKWX4a9hP3fW/0KBvfYTxLwpeQmp1KN/9u/BVjVBG5OrrSumbrIif9i5wUSfevuxc50+7MvjP5bNdnVhM9AnSo04F95/fhoByKDJCAWT6A4W2GMzF4IhuiNpCSlcK/+v6Lqb9P5cPtxiw603pN43jScRaGLTTP93LxwsvVywzk3et3JzIh0rxm38Z9WTVilTlpZUlJIBDiJpCdDYmJ4OpqZDDOzrB5s5EpREUZwWftWmNZ1IAA+Pe/jYkMa9Y0Jjts2BB63Hme6p7ujH3Yi7feMjIab29ISMqGzh/DiZ5wOv//unMaroMnUffI6zil1ufuu+GzzyDT5TQk1wGMaog77oBadbJJ8v6DpFN16BzQhg1bkznX516Stg8hZcd9dOyewnNjmvD516nkZnpwIVbx889Gm9DGjUbD/PPPG++pTh04FHuE5492ICU7BUflyNs9P+KrfbOp6VkTpRRbTxgr4T3T5Rk+vOtD0tMVdy7uQ2jsTlrXbE1iRiIJ6QnMHzSfAbcMMCcQTMtOw9nRGde3XAHY8+ge3tjwDsuP/MCuCbvoOK8jg5oPooZ7Dc6knCElK4WoxChiLsbQq2Ev3J3cWfPwGvad38fMbTPZe24vYefCCKwVyHPdnmNQ80F8GvIpn4Z8yu2NbmdJ+BI61e3EXzF/4eHswdTuUzl58SRPdn6Sdp+1A2Dh4IV8GvIpr932Gm9veZv49HgGnP2TO3tVo2/fS//++8/vp82nbXBUjuRqowrs1Z6v8kTnJ0jLTuOZNc+QnJXM5K6T+eHAD0zuNpkjcUdYH7Wed//xLlVcquDoYD1nWElIIBCiAsrLu9TYbnHunBEwvLyMarAjR6BvXyNz+flnY+R5s2YQFmY0uA8YYH3NmBhjbY1vv4WcHGNNjSlTwNPTCCpNm8K+fcbz1PxZv8ePNwYxpqcbPcVq1DCCVXr6pcZ8d3fjeUFerf4kOWAx7BuB67lbqVvXmIwxLAxOOmyhQxD0qN+Tr782guT+iGxefw0clTO33KLp2BF8fRXLlkGrVkYADQ+Hv/+Gf4zZQmM/f/78pRHT30klNiGNl572o12/3fQPaoeLsyN//22Uq2XrbP53+H8MbjEYpRQ5OfDll8ZCU27Vkli0dxHta7fn1ga3Fvo3SEhPwNvdm4ycDFwcXazaL/ad38fxxOMMuMX6Q46P19SoYfyjXf71eiz+GPWr1WfHqR3UGoZk/AAACcRJREFUcK9BS7+W3CgSCIQQV5SQYAQXV+Mm25wDy9MTIiPh1luNAHL8uFEN5uZmVHE9+qhx99+pk5Gx7NhhtMn88IOR0Rw8aBx/yy3Gl/eWLbB7t9F+U6cObMvvTOPoaHQ77tDB2F+Qt3fRc2rVqmW04xw5YnQwqFfPeA1HR2N6+MWLjSnhk5PhqaeMiR//+MPo9ly9OixZYgTB//3PeG1nZyPwbttmvIfISGNuMIuzZ43X6tr10pgcMDK4tDQYPNgInFWqwO+/G4tXgbGKYXCRX72XxMUZn7etZ0u/WiBAa12hfjp27KiFEBVPWprWy5drnZlpPA8L03rzZq0PHdL6v//VOi9P6y1bjOfr1mk9bZrWnp5aV62q9ciRWj/xhNY9exr7evTQGrR++22tc3ON6504ofXkyVq7uBj7HB219vAwHlt+atUyfjs5Gb8txwYFad27t/Wx06drfeyY1kuWaN2kibGtalWtvb2NY5ctu3RscLDWDg5af/SR1jNmGNuU0vquu7ROSNB68WKtX37ZeM8FHTxolGH27MKfV16ecW5ZwRjIW+T3qmQEQoibVnS0Ub1Tq1bhfampRtZyuT17jAke77nHuBt3dDS2+fhA+/Ywe7Zxxx4VZWQA7u5Gd+XYWKPKbeBAoy3nlwLTR3l5wXvvGdVaWhuj55OToW5dIxv45BPj+vH5s7A3b250FLg0cPNSDzJXV6NcWVlGb7PkZGP/1KlGdrNtmzGA8rffjI4KP/5ozCm2Z4+R3dxzT+k+S6kaEkKIq0hPh717jYZ7JyfjCzs83Kj66dEDAgOtR9uvXm18+X/8sVENtmOHMSJ/4ULjC3zIEGPE/bJlRjBr2dLYP2GCUaV16JARXMLCjCqqVauMKqrcXKNrcVL+ZKz16hntMWAEj5degnvvLd17lEAghBA3Ma2Nhv6EBCPL+PhjIwC1aGFkMLVrG43210MCgRBC2LmrBYJyX5hGCCFE+ZJAIIQQdk4CgRBC2DkJBEIIYeckEAghhJ2TQCCEEHZOAoEQQtg5CQRCCGHnKtyAMqVULHC8FKf6AhfKuDi2IOUsWxWhnBWhjCDlLEvlUcaGWmu/onZUuEBQWkqpkCuNqruZSDnLVkUoZ0UoI0g5y9LNVkapGhJCCDsngUAIIeycPQWCeeVdgGKScpatilDOilBGkHKWpZuqjHbTRiCEEKJo9pQRCCGEKIIEAiGEsHN2EQiUUv2UUoeUUkeVUi+Wd3kKUkpFK6XClVKhSqmQ/G0+SqnflVJH8n97l0O5vlZKnVdK7SuwrchyKcPs/M93r1KqQzmWcbpS6lT+5xmqlLq7wL6X8st4SCl1140oY/7r1ldKbVRKHVBK7VdKPZ2//ab5PK9Sxpvq81RKuSmldiilwvLL+Ub+9kZK/X97ZxdqRRmF4eftqCdJ0dQQUUMtIaxMDxYW4oVRpF1YJGgESQiR/V8UGkJ0URcJ/WBJkpRaSlqW5k1iqVRQqVRqRyw7qVDib6ElhJmtLr61z5m2e59jkHuGZj0w7G/WDMN73j1z1nzfN3uNtrieVZJ6eLzZ19t8+7CcdS6VtC/j5xiP53INtVPvrfb/lwVoAn4ARgA9gB3AqLx1ZfTtBwZUxeYDc709F3g2B10TgRagtStdwBTgA0DAeGBLjhqfAh6rse8o/+6bgeF+TjQ1SOcgoMXbvYE9rqcwfnaisVB+uie9vN0d2OIevQ3M8PgiYLa37wcWeXsGsKpB33k9nUuBaTX2z+Uaqixl6BFcB7SZ2V4z+wNYCUzNWVNXTAWWeXsZcFujBZjZJ8AvVeF6uqYCb1jiC6CvpEE5aazHVGClmZ0ys31AG+ncOO+Y2UEz+8rbvwG7gcEUyM9ONNYjFz/dk5O+2t0XAyYBqz1e7WXF49XAjZKUo8565HINVShDIhgM/JhZ/4nOT/BGY8AGSV9KutdjA83soLcPAQPzkXYW9XQVzeMHvXv9emZYrRAafWhiLOkOsZB+VmmEgvkpqUnSduAI8CGpN3LczP6soaVdp28/AfTPQ6eZVfx8xv18QVJztU6nod95GRJB0ZlgZi3AZOABSROzGy31Gwv3jG9RdQGvAJcBY4CDwHP5yulAUi/gXeBRM/s1u60oftbQWDg/zeyMmY0BhpB6IVfkLKkm1TolXQU8QdJ7LdAPmJOjxHbKkAgOAEMz60M8VgjM7IB/HgHWkE7sw5VuoX8eyU/hP6inqzAem9lhvwD/AhbTMVyRq0ZJ3Un/YFeY2XseLpSftTQW1U/XdhzYDFxPGkrpVkNLu07f3gf4OSedt/gQnJnZKWAJBfGzDIlgGzDSnyroQZowWpezJgAkXSSpd6UN3Ay0kvTN9N1mAu/no/As6ulaB9ztTz6MB05khjwaStW46u0kPyFpnOFPkQwHRgJbG6RJwGvAbjN7PrOpMH7W01g0PyVdIqmvt3sCN5HmMzYD03y3ai8rHk8DNnnvKw+d32YSv0jzGFk/87uGGjkznddCmpHfQxpLnJe3noyuEaQnL3YAuyraSGOYG4HvgY+Afjloe4s0FHCaNF45q54u0pMOC93fb4BxOWp80zXsJF1cgzL7z3ON3wGTG+jlBNKwz05guy9TiuRnJxoL5ScwGvja9bQCT3p8BCkRtQHvAM0ev9DX23z7iJx1bnI/W4HldDxZlMs1VFmixEQQBEHJKcPQUBAEQdAJkQiCIAhKTiSCIAiCkhOJIAiCoOREIgiCICg5kQiCwJF0JlMVcrv+w0q1koYpUyU1CIpEt653CYLS8LulkgBBUCqiRxAEXaD0zoj5Su+N2Crpco8Pk7TJC4htlHSpxwdKWuO16HdIusEP1SRpsden3+C/OEXSw0rvAdgpaWVOf2ZQYiIRBEEHPauGhqZntp0ws6uBl4EXPfYSsMzMRgMrgAUeXwB8bGbXkN6XsMvjI4GFZnYlcBy4w+NzgbF+nPvO1x8XBPWIXxYHgSPppJn1qhHfD0wys71emO2QmfWXdIxUcuG0xw+a2QBJR4EhlgqLVY4xjFSKeKSvzwG6m9nTktYDJ4G1wFrrqGMfBA0hegRBcG5Ynfa/4VSmfYaOObpbSXVmWoBtmSqaQdAQIhEEwbkxPfP5ubc/I1WzBbgL+NTbG4HZ0P5ykj71DirpAmComW0m1abvA5zVKwmC80nceQRBBz39jVIV1ptZ5RHSiyXtJN3V3+mxh4Alkh4HjgL3ePwR4FVJs0h3/rNJVVJr0QQs92QhYIGl+vVB0DBijiAIusDnCMaZ2bG8tQTB+SCGhoIgCEpO9AiCIAhKTvQIgiAISk4kgiAIgpITiSAIgqDkRCIIgiAoOZEIgiAISs7fapReCiYHVDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"plot_history(history)\";\n",
       "                var nbb_formatted_code = \"plot_history(history)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.720685Z",
     "start_time": "2020-05-25T20:59:43.865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9247056661481613"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_formatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_auc = roc_auc_score(\n",
    "    y_true=y_valid, y_score=model.predict(X_valid_preproc).reshape(-1),\n",
    ")\n",
    "model_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T21:00:07.722364Z",
     "start_time": "2020-05-25T20:59:43.867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242110564268156"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_formatted_code = \"model_auc = roc_auc_score(\\n    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\\n)\\nmodel_auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_auc = roc_auc_score(\n",
    "    y_true=y_test, y_score=model.predict(X_test_preproc).reshape(-1),\n",
    ")\n",
    "model_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# valid 0.9282381974389771 test 0.9262939626480025 conv_dim=[64], lconv_dim=[128, 64, 32] patience 50\";\n",
       "                var nbb_formatted_code = \"# valid 0.9282381974389771 test 0.9262939626480025 conv_dim=[64], lconv_dim=[128, 64, 32] patience 50\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid 0.9282381974389771 test 0.9262939626480025 conv_dim=[64], lconv_dim=[128, 64, 32] patience 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"SAMPLE_NB = 1000\";\n",
       "                var nbb_formatted_code = \"SAMPLE_NB = 1000\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_NB = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"sample = X_valid_preproc[:SAMPLE_NB]\";\n",
       "                var nbb_formatted_code = \"sample = X_valid_preproc[:SAMPLE_NB]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = X_valid_preproc[:SAMPLE_NB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"model_pred = model.predict(sample)\\nmodel_pred.shape\";\n",
       "                var nbb_formatted_code = \"model_pred = model.predict(sample)\\nmodel_pred.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pred = model.predict(sample)\n",
    "model_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])\";\n",
       "                var nbb_formatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"new_model_pred, feature_inter = new_model.predict(sample)\";\n",
       "                var nbb_formatted_code = \"new_model_pred, feature_inter = new_model.predict(sample)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_pred, feature_inter = new_model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"assert np.all(model_pred == new_model_pred)\";\n",
       "                var nbb_formatted_code = \"assert np.all(model_pred == new_model_pred)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert np.all(model_pred == new_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"feature_inter.shape\";\n",
       "                var nbb_formatted_code = \"feature_inter.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"for idx in range(sample.shape[1]):\\n    one_col = np.zeros(sample.shape)\\n    one_col[:, idx] = sample[:, idx]\\n    _, feature_inter_one_col = new_model.predict(one_col)\\n    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\n    assert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_formatted_code = \"for idx in range(sample.shape[1]):\\n    one_col = np.zeros(sample.shape)\\n    one_col[:, idx] = sample[:, idx]\\n    _, feature_inter_one_col = new_model.predict(one_col)\\n    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\n    assert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(sample.shape[1]):\n",
    "    one_col = np.zeros(sample.shape)\n",
    "    one_col[:, idx] = sample[:, idx]\n",
    "    _, feature_inter_one_col = new_model.predict(one_col)\n",
    "    assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\n",
    "    assert np.sum(feature_inter_one_col - feature_inter) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"idx = 0\\none_col = np.zeros(sample.shape)\\none_col[:, idx] = sample[:, idx]\\n_, feature_inter_one_col = new_model.predict(one_col)\\nassert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\nassert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_formatted_code = \"idx = 0\\none_col = np.zeros(sample.shape)\\none_col[:, idx] = sample[:, idx]\\n_, feature_inter_one_col = new_model.predict(one_col)\\nassert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\\nassert np.sum(feature_inter_one_col - feature_inter) > 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "one_col = np.zeros(sample.shape)\n",
    "one_col[:, idx] = sample[:, idx]\n",
    "_, feature_inter_one_col = new_model.predict(one_col)\n",
    "assert np.all(feature_inter_one_col[:, idx, :] == feature_inter[:, idx, :])\n",
    "assert np.sum(feature_inter_one_col - feature_inter) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"feature_inter_one_col[:, 0, :].shape\";\n",
       "                var nbb_formatted_code = \"feature_inter_one_col[:, 0, :].shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_inter_one_col[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f957af279d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"new_model.layers[-1]\";\n",
       "                var nbb_formatted_code = \"new_model.layers[-1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"model.get_weights()[-2].shape\";\n",
       "                var nbb_formatted_code = \"model.get_weights()[-2].shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.get_weights()[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])\";\n",
       "                var nbb_formatted_code = \"new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=[model.input], outputs=[model.output, model.layers[-2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 9.77 s, total: 22.7 s\n",
      "Wall time: 6.67 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"%%time\\n_, new_train_logistic = new_model.predict(X_train_preproc)\\n_, new_valid_logistic = new_model.predict(X_valid_preproc)\\n_, new_test_logistic = new_model.predict(X_test_preproc)\";\n",
       "                var nbb_formatted_code = \"%%time\\n_, new_train_logistic = new_model.predict(X_train_preproc)\\n_, new_valid_logistic = new_model.predict(X_valid_preproc)\\n_, new_test_logistic = new_model.predict(X_test_preproc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "_, new_train_logistic = new_model.predict(X_train_preproc)\n",
    "_, new_valid_logistic = new_model.predict(X_valid_preproc)\n",
    "_, new_test_logistic = new_model.predict(X_test_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\";\n",
       "                var nbb_formatted_code = \"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"lreg = LogisticRegression(max_iter=1000, n_jobs=-1)\";\n",
       "                var nbb_formatted_code = \"lreg = LogisticRegression(max_iter=1000, n_jobs=-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg = LogisticRegression(max_iter=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26072, 448)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"new_train_logistic.shape\";\n",
       "                var nbb_formatted_code = \"new_train_logistic.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_train_logistic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.6 ms, sys: 88.6 ms, total: 115 ms\n",
      "Wall time: 2min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"%%time\\nlreg.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"%%time\\nlreg.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "lreg.fit(new_train_logistic, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9236967465427502"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_valid, y_score=lreg.predict_proba(new_valid_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9237837351679689"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_test, y_score=lreg.predict_proba(new_test_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"lreg_cv = LogisticRegressionCV(Cs=10, max_iter=300, n_jobs=-1, cv=5, random_state=0)\";\n",
       "                var nbb_formatted_code = \"lreg_cv = LogisticRegressionCV(Cs=10, max_iter=300, n_jobs=-1, cv=5, random_state=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lreg_cv = LogisticRegressionCV(Cs=10, max_iter=300, n_jobs=-1, cv=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 s, sys: 572 ms, total: 3.95 s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=300, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"%%time\\nlreg_cv.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_formatted_code = \"%%time\\nlreg_cv.fit(new_train_logistic, y_train.reshape(-1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "lreg_cv.fit(new_train_logistic, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924271040489364"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg_cv.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_valid, y_score=lreg_cv.predict_proba(new_valid_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_valid, y_score=lreg_cv.predict_proba(new_valid_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241963976451931"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg_cv.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_formatted_code = \"roc_auc_score(\\n    y_true=y_test, y_score=lreg_cv.predict_proba(new_test_logistic)[:, 1],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score(\n",
    "    y_true=y_test, y_score=lreg_cv.predict_proba(new_test_logistic)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
