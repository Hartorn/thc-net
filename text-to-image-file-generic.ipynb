{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:29.741294Z",
     "start_time": "2020-05-01T14:21:29.085352Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:30.369600Z",
     "start_time": "2020-05-01T14:21:29.743473Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /work/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:30.396504Z",
     "start_time": "2020-05-01T14:21:30.372831Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_name = \"santander-customer-satisfaction\"\n",
    "# target = \"TARGET\"\n",
    "# dataset_name = \"census-income\"\n",
    "# target = \"taxable income amount\"\n",
    "dataset_name = \"bank-marketing\"\n",
    "target = \"y\"\n",
    "# dataset_name = \"open-payments\"\n",
    "# target = \"status\"\n",
    "# dataset_name = \"bnp-cardif\"\n",
    "# target = \"target\"\n",
    "# dataset_name = \"give-me-some-credit\"\n",
    "# target = \"SeriousDlqin2yrs\"\n",
    "# dataset_name = \"springleaf-marketing-response\" #(9h)\n",
    "# target = \"target\"\n",
    "# dataset_name = \"segment\"\n",
    "# target = \"class\"\n",
    "# dataset_name = \"rl\"\n",
    "# target = \"target\"\n",
    "# dataset_name = \"portoseguro\"\n",
    "# target = \"target\"\n",
    "# dataset_name = \"road-safety\"  # (3h)\n",
    "# target = \"Sex_of_Driver_df_res\"\n",
    "# dataset_name = \"titanic\"\n",
    "# target = \"Survived\"\n",
    "# dataset_name = \"cat-in-the-dat-ii\"  # 20min\n",
    "# target = \"target\"\n",
    "\n",
    "panda_kwargs = {}\n",
    "\n",
    "FEATURE_SIZE = 32\n",
    "IMAGE_SIZE = None  # 96\n",
    "CUT_LENGTH = None\n",
    "ONE_CHANNEL = True\n",
    "\n",
    "\n",
    "FONT_FOLDER = Path(os.getcwd())\n",
    "DATASET_FOLDER = Path(os.getcwd()) / f\"data/{dataset_name}\"\n",
    "DATASET_FILENAME = \"train_bench.csv\"\n",
    "DATASET_URL = None\n",
    "\n",
    "TAILORED_COLUMN = \"Set\"\n",
    "MAX_MEMORY_USE = 1  # IN GB\n",
    "NB_CHANNEL = 1 if ONE_CHANNEL else 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:04:39.963383Z",
     "start_time": "2020-04-17T13:04:39.955914Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Import + utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.445363Z",
     "start_time": "2020-05-01T14:21:30.400540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gzip\n",
    "import gc\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor as PoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.477731Z",
     "start_time": "2020-05-01T14:21:35.449119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def download(url, out, force=False, verify=True):\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if force:\n",
    "        print(f\"Removing file at {str(out)}\")\n",
    "        out.unlink()\n",
    "\n",
    "    if out.exists():\n",
    "        print(\"File already exists.\")\n",
    "        return\n",
    "    print(f\"Downloading {url} at {str(out)} ...\")\n",
    "    # open in binary mode\n",
    "    with out.open(mode=\"wb\") as file:\n",
    "        # get request\n",
    "        response = get(url, verify=verify)\n",
    "        for chunk in response.iter_content(100000):\n",
    "            # write to file\n",
    "            file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.574332Z",
     "start_time": "2020-05-01T14:21:35.480063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def do_parallel_numpy(map_func, iter_params, constant_params=None):\n",
    "    repeated_params = (\n",
    "        [] if constant_params is None else list(map(repeat, constant_params))\n",
    "    )\n",
    "    results = None\n",
    "    with PoolExecutor() as executor:\n",
    "        results = np.stack(\n",
    "            list(executor.map(map_func, *iter_params, *repeated_params)), axis=0\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.660910Z",
     "start_time": "2020-05-01T14:21:35.576424Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_numpy_as_image_gz(arr, path, one_channel=False):\n",
    "    mode = \"L\" if one_channel else \"RGB\"\n",
    "\n",
    "    im = Image.fromarray(arr, mode=mode)\n",
    "    output = io.BytesIO()\n",
    "    im.save(output, \"jpeg\", optimize=True)\n",
    "    with gzip.open(path, \"wb\") as f:\n",
    "        f.write(output.getvalue())\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Download font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.715560Z",
     "start_time": "2020-05-01T14:21:35.666831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "font_url = \"https://ff.static.1001fonts.net/r/o/roboto-condensed.regular.ttf\"\n",
    "\n",
    "dataset_path = DATASET_FOLDER / DATASET_FILENAME\n",
    "out_font = FONT_FOLDER / f\"RobotoCondensed-Regular.ttf\"\n",
    "\n",
    "if DATASET_URL is not None:\n",
    "    download(DATASET_URL, dataset_path)\n",
    "download(font_url, out_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.730478Z",
     "start_time": "2020-05-01T14:21:35.718356Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def format_number(nb):\n",
    "    return np.format_float_scientific(\n",
    "        nb, precision=9, unique=False, pad_left=None, exp_digits=2, sign=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Numpy to img preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.745110Z",
     "start_time": "2020-05-01T14:21:35.732633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://he-arc.github.io/livre-python/pillow/index.html#methodes-de-dessin\n",
    "# https://stackoverflow.com/questions/26649716/how-to-show-pil-image-in-ipython-notebook\n",
    "# https://stackoverflow.com/questions/384759/how-to-convert-a-pil-image-into-a-numpy-array\n",
    "# line = np.array(pic, dtypes=\"uint8\")\n",
    "# from https://arxiv.org/pdf/1902.02160.pdf page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:35.801211Z",
     "start_time": "2020-05-01T14:21:35.747394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def word_to_square_image(text, size, cut_length=None, one_channel=False):\n",
    "\n",
    "    if not isinstance(text, str) and np.isfinite(text):\n",
    "        text = format_number(text)\n",
    "    truncated = text[:cut_length] if cut_length is not None else text\n",
    "    max_x = np.ceil(np.sqrt(len(truncated))).astype(\"int\")\n",
    "    character_size = np.floor(size / max_x).astype(\"int\")\n",
    "    padding = np.floor((size - (max_x * character_size)) / 2).astype(\"int\")\n",
    "    # Do we need pt to px conversion ? Seems like not\n",
    "    # font_size =  int(np.floor(character_size*0.75))\n",
    "    font_size = character_size\n",
    "\n",
    "    fnt = ImageFont.truetype(out_font.as_posix(), font_size)\n",
    "\n",
    "    # 1 (1-bit pixels, black and white, stored with one pixel per byte)\n",
    "    # L (8-bit pixels, black and white)\n",
    "    # RGB (3x8-bit pixels, true color)\n",
    "    # https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes\n",
    "    mode = \"L\" if one_channel else \"RGB\"\n",
    "    WHITE = 255 if one_channel else (255, 255, 255)\n",
    "    BLACK = 0 if one_channel else (0, 0, 0)\n",
    "\n",
    "    image = Image.new(mode, (size, size), BLACK)\n",
    "    # Obtention du contexte graphique\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for letter in truncated:\n",
    "        draw.text(\n",
    "            (padding + x * character_size, padding + y * character_size),\n",
    "            letter,\n",
    "            font=fnt,\n",
    "            fill=WHITE,\n",
    "        )\n",
    "        if x + 1 < max_x:\n",
    "            x += 1\n",
    "        else:\n",
    "            y += 1\n",
    "            x = 0\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.186989Z",
     "start_time": "2020-05-01T14:21:35.803087Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_1 = word_to_square_image(\"Example\", 24, cut_length=None, one_channel=False)\n",
    "print(img_1.shape)\n",
    "imshow(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.358077Z",
     "start_time": "2020-05-01T14:21:36.188608Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_2 = word_to_square_image(\"Example\", 32, cut_length=None, one_channel=True)\n",
    "print(img_2.shape)\n",
    "imshow(img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.531557Z",
     "start_time": "2020-05-01T14:21:36.359684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_2 = word_to_square_image(\"+1.550000000e+01\", 32, cut_length=None, one_channel=True)\n",
    "print(img_2.shape)\n",
    "imshow(img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.695949Z",
     "start_time": "2020-05-01T14:21:36.535896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imshow(\n",
    "    word_to_square_image(\n",
    "        \"This is a long sentence\", 24, cut_length=None, one_channel=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.930010Z",
     "start_time": "2020-05-01T14:21:36.699654Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imshow(\n",
    "    word_to_square_image(\"This is a long sentence\", 32, cut_length=9, one_channel=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:36.978671Z",
     "start_time": "2020-05-01T14:21:36.931762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def features_to_square_image(\n",
    "    features, image_size=224, cut_length=None, one_channel=False\n",
    "):\n",
    "    nb_channel = 1 if one_channel else 3\n",
    "    square_nb = np.ceil(np.sqrt(len(features))).astype(\"int\")\n",
    "    word_size = np.floor(image_size / square_nb).astype(\"int\")\n",
    "    max_features = len(features)\n",
    "    padding = np.floor((image_size - square_nb * word_size) / 2).astype(\"int\")\n",
    "    if one_channel:\n",
    "        result_image = np.zeros((image_size, image_size), dtype=\"uint8\")\n",
    "    else:\n",
    "        result_image = np.zeros((image_size, image_size, nb_channel), dtype=\"uint8\")\n",
    "    results = []\n",
    "    i_feature = 0\n",
    "    features_str = features.astype(\"str\")\n",
    "    for x in range(0, square_nb):\n",
    "        if i_feature is None:\n",
    "            break\n",
    "        for y in range(0, square_nb):\n",
    "            i_feature = x * (square_nb) + y\n",
    "            if i_feature >= max_features:\n",
    "                i_feature = None\n",
    "                break\n",
    "            x_pos = x * word_size + padding\n",
    "            y_pos = y * word_size + padding\n",
    "            result_image[\n",
    "                x_pos : x_pos + word_size, y_pos : y_pos + word_size\n",
    "            ] = word_to_square_image(\n",
    "                features_str[i_feature],\n",
    "                size=word_size,\n",
    "                cut_length=cut_length,\n",
    "                one_channel=one_channel,\n",
    "            )\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.159413Z",
     "start_time": "2020-05-01T14:21:36.980320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_3 = features_to_square_image(\n",
    "    np.array(\n",
    "        [\n",
    "            10,\n",
    "            \"test\",\n",
    "            1.0,\n",
    "            True,\n",
    "            np.nan,\n",
    "            \"blabla\",\n",
    "            150000,\n",
    "            \"a long sentence just to see\",\n",
    "            \"A\",\n",
    "        ]\n",
    "    ),\n",
    "    image_size=3 * 16,\n",
    ")\n",
    "print(img_3.shape)\n",
    "imshow(img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.179263Z",
     "start_time": "2020-05-01T14:21:37.161359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def features_to_square_image_params(values, params):\n",
    "    return features_to_square_image(\n",
    "        values,\n",
    "        image_size=params[\"image_size\"],\n",
    "        cut_length=params[\"cut_length\"],\n",
    "        one_channel=params[\"one_channel\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load info from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.379809Z",
     "start_time": "2020-05-01T14:21:37.181055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = pd.read_csv(dataset_path, **panda_kwargs, nrows=1).columns.tolist()\n",
    "print(len(columns))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.601815Z",
     "start_time": "2020-05-01T14:21:37.381845Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_values = pd.read_csv(\n",
    "    dataset_path, **panda_kwargs, usecols=[target]\n",
    ").values.reshape(-1)\n",
    "CLASSNAMES = np.unique(target_values).astype(\"str\")\n",
    "NB_LINES = target_values.shape[0]\n",
    "del target_values\n",
    "print(NB_LINES)\n",
    "print(CLASSNAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.696908Z",
     "start_time": "2020-05-01T14:21:37.603753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "split = None\n",
    "if TAILORED_COLUMN not in columns:\n",
    "    split = np.random.choice(\n",
    "        [\"train\", \"valid\", \"test\"], p=[0.8, 0.1, 0.1], size=(NB_LINES,)\n",
    "    )\n",
    "else:\n",
    "    split = pd.read_csv(\n",
    "        dataset_path, **panda_kwargs, usecols=[TAILORED_COLUMN]\n",
    "    ).values.reshape(-1)\n",
    "\n",
    "\n",
    "train_indices = np.argwhere(split == \"train\").reshape(-1)\n",
    "# np.random.shuffle(train_indices)\n",
    "valid_indices = np.argwhere(split == \"valid\").reshape(-1)\n",
    "test_indices = np.argwhere(split == \"test\").reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.716585Z",
     "start_time": "2020-05-01T14:21:37.700703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "used_columns = list(set(columns) - set([TAILORED_COLUMN, target]))\n",
    "used_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.813210Z",
     "start_time": "2020-05-01T14:21:37.719714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "extract_df = pd.read_csv(\n",
    "    dataset_path, **panda_kwargs, nrows=1000, usecols=used_columns, low_memory=False\n",
    ")\n",
    "extract_df.dtypes\n",
    "nb_idx = (extract_df.dtypes == \"int64\") | (extract_df.dtypes == \"float64\")\n",
    "nb_idx = extract_df.columns[nb_idx]\n",
    "del extract_df\n",
    "nb_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate image size (width, and memory weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.832168Z",
     "start_time": "2020-05-01T14:21:37.815154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "square_side_nb_feature = np.ceil(np.sqrt(len(used_columns))).astype(\"int\")\n",
    "IMAGE_SIZE = square_side_nb_feature * FEATURE_SIZE if IMAGE_SIZE is None else IMAGE_SIZE\n",
    "memory_image_size = (\n",
    "    square_side_nb_feature ** 2 * FEATURE_SIZE ** 2 * NB_CHANNEL\n",
    ")  # in bytes\n",
    "chunk_size = np.floor((MAX_MEMORY_USE * 1024 ** 3) / memory_image_size).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.872098Z",
     "start_time": "2020-05-01T14:21:37.834083Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.890570Z",
     "start_time": "2020-05-01T14:21:37.874857Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "memory_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.910434Z",
     "start_time": "2020-05-01T14:21:37.893061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CHUNK = chunk_size\n",
    "CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:37.929701Z",
     "start_time": "2020-05-01T14:21:37.912432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"image_size\": IMAGE_SIZE,\n",
    "    \"cut_length\": CUT_LENGTH,\n",
    "    \"one_channel\": ONE_CHANNEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T13:09:05.896414Z",
     "start_time": "2020-04-17T13:09:05.860854Z"
    }
   },
   "source": [
    "## Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:38.921188Z",
     "start_time": "2020-05-01T14:21:37.931481Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = {\n",
    "    \"train\": [],\n",
    "    \"valid\": [],\n",
    "    \"test\": [],\n",
    "}\n",
    "for set_label in [\"train\", \"valid\", \"test\"]:\n",
    "    prep_data_folder = DATASET_FOLDER / f\"prep_data/{IMAGE_SIZE}/{set_label}/\"\n",
    "    if prep_data_folder.exists():\n",
    "        shutil.rmtree(prep_data_folder)\n",
    "    prep_data_folder.mkdir(parents=True, exist_ok=True)\n",
    "    for classname in CLASSNAMES:\n",
    "        out_folder = prep_data_folder / classname\n",
    "        out_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:38.929375Z",
     "start_time": "2020-05-01T14:21:38.922911Z"
    }
   },
   "outputs": [],
   "source": [
    "prep_data_folder = DATASET_FOLDER / \"prep_data\" / str(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:24:04.267728Z",
     "start_time": "2020-05-01T14:21:38.931103Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, chunk in tqdm(\n",
    "    enumerate(\n",
    "        pd.read_csv(\n",
    "            dataset_path,\n",
    "            **panda_kwargs,\n",
    "            chunksize=CHUNK,\n",
    "            usecols=used_columns + [target]\n",
    "        )\n",
    "    ),\n",
    "    total=(NB_LINES // CHUNK) + (1 if NB_LINES % CHUNK > 0 else 0),\n",
    "):\n",
    "    # for idx in nb_idx:\n",
    "    #    chunk[idx] = chunk[idx].apply(format_number)\n",
    "\n",
    "    # chunk[nb_idx] = format_number(chunk[nb_idx])\n",
    "    X = chunk[used_columns].values\n",
    "    Y = chunk[target].values.reshape(-1)  # .astype(\"str\")\n",
    "    image_X = do_parallel_numpy(features_to_square_image_params, [X], [params])\n",
    "\n",
    "    chunk_list = []\n",
    "    for j, label in enumerate(Y):\n",
    "        idx = i * CHUNK + j\n",
    "        set_label = (\n",
    "            \"train\"\n",
    "            if idx in train_indices\n",
    "            else \"valid\"\n",
    "            if idx in valid_indices\n",
    "            else \"test\"\n",
    "        )\n",
    "        full_path = (\n",
    "            prep_data_folder\n",
    "            / set_label\n",
    "            / str(label)\n",
    "            / (str(j + i * CHUNK) + \".jpeg.gz\")\n",
    "        ).as_posix()\n",
    "        chunk_list.append(full_path)\n",
    "        file_list[set_label].append(full_path)\n",
    "\n",
    "    assert all(\n",
    "        do_parallel_numpy(\n",
    "            save_numpy_as_image_gz, [image_X, chunk_list], [ONE_CHANNEL]\n",
    "        ).reshape(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:24:04.342806Z",
     "start_time": "2020-05-01T14:24:04.269524Z"
    }
   },
   "outputs": [],
   "source": [
    "json_file = DATASET_FOLDER / f\"prep_data/{IMAGE_SIZE}/file_list.json\"\n",
    "\n",
    "with json_file.open(mode=\"w\") as fp:\n",
    "    json.dump(file_list, fp)\n",
    "json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:24:04.484925Z",
     "start_time": "2020-05-01T14:24:04.344989Z"
    }
   },
   "outputs": [],
   "source": [
    "classnames_file = DATASET_FOLDER / f\"prep_data/{IMAGE_SIZE}/classnames.json\"\n",
    "\n",
    "with classnames_file.open(mode=\"w\") as fp:\n",
    "    json.dump(CLASSNAMES.tolist(), fp)\n",
    "classnames_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
